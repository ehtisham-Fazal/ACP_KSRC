{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ehtisham-Fazal/ACP_SRC/blob/main/ACP_SRC_344_Python_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ec8db92f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec8db92f",
        "outputId": "ee6972c4-1fa3-4f96-d50e-e4a5b7d31d1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=8bd7e72fb4e345be17c7308ade266f01ea8bbdc02a53520753010193b3fece81\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ],
      "source": [
        "import sys, os, re, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import sample\n",
        "\n",
        "## Models\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, BatchNormalization, Dropout\n",
        "from keras import metrics\n",
        "from keras import optimizers\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "import numpy.linalg as LA\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "## Perfmetrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report, accuracy_score, matthews_corrcoef, balanced_accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.metrics import auc, average_precision_score, precision_recall_curve, roc_curve\n",
        "\n",
        "## utilities\n",
        "from matplotlib import pyplot as plt\n",
        "!pip install wget\n",
        "import wget\n",
        "\n",
        "\n",
        "## pre-processing\n",
        "from sklearn.preprocessing import normalize, Normalizer\n",
        "from sklearn.decomposition import KernelPCA\n",
        "from imblearn.over_sampling import ADASYN, SMOTE, SVMSMOTE, KMeansSMOTE, BorderlineSMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4231e992",
      "metadata": {
        "id": "4231e992"
      },
      "outputs": [],
      "source": [
        "file1_path = 'https://raw.githubusercontent.com/NLPrinceton/sparse_recovery/master/solvers.py'\n",
        "wget.download(file1_path, 'solvers.py')\n",
        "from solvers import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0f32eaa9",
      "metadata": {
        "id": "0f32eaa9"
      },
      "outputs": [],
      "source": [
        "def load_seq_data(data_path,label):\n",
        "  dataset = pd.read_csv(data_path,names=None,index_col=0, header=None)\n",
        "  seq = []\n",
        "  sample_count = 0\n",
        "\n",
        "  for row in dataset.iterrows():\n",
        "    if(row[0]!='>'):\n",
        "      sample_count = sample_count +1\n",
        "      array = [label, row[0]]    \n",
        "      name, sequence = array[0].split()[0], re.sub('[^ARNDCQEGHILKMFPSTWYV-]', '-', ''.join(array[1:]).upper())\n",
        "      seq.append([name, sequence])\n",
        "\n",
        "  print('# of ' + label + ' samples',sample_count)\n",
        "  return seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "68c169cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68c169cb",
        "outputId": "aeb43722-2fb8-4066-ef72-35d3264a562d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of POS samples 138\n",
            "# of NEG samples 206\n",
            "138 206 344\n"
          ]
        }
      ],
      "source": [
        "pos_all_seq_path = 'https://raw.githubusercontent.com/Shujaat123/ACP_LSE/main/dataset_acp_JTB_2014/1-s2.0-S0022519313004190-mmc1.txt'\n",
        "neg_all_seq_path = 'https://raw.githubusercontent.com/Shujaat123/ACP_LSE/main/dataset_acp_JTB_2014/1-s2.0-S0022519313004190-mmc2.txt'\n",
        "\n",
        "pos_all_seq = load_seq_data(pos_all_seq_path,'POS')\n",
        "neg_all_seq = load_seq_data(neg_all_seq_path,'NEG')\n",
        "\n",
        "ALL_seq = pos_all_seq + neg_all_seq\n",
        "\n",
        "print(len(pos_all_seq), len(neg_all_seq), len(ALL_seq))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6b3c418d",
      "metadata": {
        "id": "6b3c418d"
      },
      "outputs": [],
      "source": [
        "def yoden_index(y, y_pred):\n",
        "  epsilon = 1e-30\n",
        "  tn, fp, fn, tp = confusion_matrix(y, y_pred, labels=[0,1]).ravel()\n",
        "  j = (tp/(tp + fn + epsilon)) + (tn/(tn+fp + epsilon)) - 1\n",
        "  return j\n",
        "\n",
        "def pmeasure(y, y_pred):\n",
        "    epsilon = 1e-30\n",
        "    tn, fp, fn, tp = confusion_matrix(y, y_pred, labels=[0,1]).ravel()\n",
        "    sensitivity = tp / (tp + fn + epsilon)\n",
        "    specificity = tn / (tn + fp + epsilon)\n",
        "    f1score = (2 * tp) / (2 * tp + fp + fn + epsilon)\n",
        "    return ({'Sensitivity': sensitivity, 'Specificity': specificity, 'F1-Score': f1score})\n",
        "    \n",
        "def Calculate_Stats(y_actual,y_pred):\n",
        "  acc = accuracy_score(y_actual, y_pred)\n",
        "  sen = pmeasure(y_actual, y_pred)['Sensitivity']\n",
        "  spe = pmeasure(y_actual, y_pred)['Specificity']\n",
        "  f1 = pmeasure(y_actual, y_pred)['F1-Score']\n",
        "  mcc = matthews_corrcoef(y_actual, y_pred)\n",
        "  bacc = balanced_accuracy_score(y_actual, y_pred)\n",
        "  yi = yoden_index(y_actual, y_pred)\n",
        "  #auc = roc_auc_score(y_actual, y_pred)\n",
        "  \n",
        "  #pre, rec, _ = precision_recall_curve(y_actual, y_score, pos_label=1)\n",
        "  #fpr, tpr, _ = roc_curve(y_actual, y_score, pos_label=1)\n",
        "  #auroc = auc(fpr, tpr)\n",
        "  #aupr = auc(rec, pre)\n",
        "\n",
        "  return acc, sen, spe, f1, mcc, bacc, yi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c392a070",
      "metadata": {
        "id": "c392a070"
      },
      "outputs": [],
      "source": [
        "def Test_SRC(A,delta_y,DATA,LABEL,solver='BP',verbose=0, x0=None, ATinvAAT=None, nnz=None, positive=False, tol=1E-4, niter=100, biter=32):\n",
        "  # A = X_train\n",
        "  # DATA = X_test\n",
        "  # LABEL = y_test\n",
        "  LABEL_PRED = []\n",
        "  count = 0\n",
        "  for ind in range(0,DATA.shape[1]):\n",
        "    b = DATA[:,ind]\n",
        "    if(solver=='BP'):\n",
        "      # x = BasisPursuit(A, b, x0=None, ATinvAAT=None, positive=False, tol=1E-4, niter=100, biter=32)\n",
        "      x = BasisPursuit(A, b, x0=x0, ATinvAAT=ATinvAAT, positive=positive, tol=tol, niter=niter, biter=biter)\n",
        "    elif(solver=='MP'):\n",
        "      # x = MatchingPursuit(A, b, tol=1E-4, nnz=None, positive=False)\n",
        "      x = MatchingPursuit(A, b, tol=tol, nnz=nnz, positive=positive)\n",
        "    \n",
        "    # x = NonnegativeBP(A, b, x0=None, tol=1E-4, niter=100, biter=32)\n",
        "    # x = OrthogonalMP(A, b, tol=1E-4, nnz=None, positive=False)\n",
        "    # x = OrthogonalMP(A, b, tol=1E-4, nnz=None, positive=True)\n",
        "    # x = MatchingPursuit(A, b, tol=1E-4, nnz=None, positive=False, orthogonal=False)\n",
        "    # x = MatchingPursuit(A, b, tol=1E-4, nnz=None, positive=True, orthogonal=False)\n",
        "    \n",
        "    label_out = delta_rule(A,delta_y,x,b)\n",
        "    if (verbose):\n",
        "      check = label_out==LABEL[ind]\n",
        "      if (check):\n",
        "        count = count + 1\n",
        "      accuracy = 100*count/(ind+1)\n",
        "      print(ind+1, count, accuracy, LABEL[ind], label_out, check)\n",
        "    LABEL_PRED.append(label_out)\n",
        "\n",
        "  return np.array(LABEL_PRED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9a0e5eaa",
      "metadata": {
        "id": "9a0e5eaa"
      },
      "outputs": [],
      "source": [
        "def delta_rule(A,delta_y,x,b):\n",
        "  # num_samples_per_class = int(x.shape[0]/2)\n",
        "  delta1 = 0*x\n",
        "  delta2 = 0*x\n",
        "  # delta1[0:num_samples_per_class] = x[0:num_samples_per_class]\n",
        "  # delta2[num_samples_per_class:] = x[num_samples_per_class:]\n",
        "\n",
        "  delta1[delta_y==1]=x[delta_y==1]\n",
        "  delta2[delta_y==0]=x[delta_y==0]\n",
        "\n",
        "  y1 = np.matmul(A,delta1)\n",
        "  y2 = np.matmul(A,delta2)\n",
        "  # print(delta1.shape, delta2.shape, y1.shape, y2.shape)\n",
        "  r1 = np.linalg.norm(y1-b)\n",
        "  r2 = np.linalg.norm(y2-b)\n",
        "\n",
        "  if(r1<r2):\n",
        "    label = 1\n",
        "  else:\n",
        "    label = 0\n",
        "\n",
        "  return label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "21031082",
      "metadata": {
        "id": "21031082"
      },
      "outputs": [],
      "source": [
        "def Convert_Seq2CKSAAP(train_seq, gap=8):\n",
        "  cksaapfea = []\n",
        "  seq_label = []\n",
        "  for sseq in train_seq:\n",
        "    temp= CKSAAP([sseq], gap=8)\n",
        "    cksaapfea.append(temp[1][1:])\n",
        "    seq_label.append(sseq[0])\n",
        "\n",
        "  x = np.array(cksaapfea)\n",
        "  y = np.array(seq_label)\n",
        "  y[y=='POS']=1\n",
        "  y[y=='NEG']=0\n",
        "  y = to_categorical(y)\n",
        "  print('num pos:', sum(y[:,0]==1), 'num neg:', sum(y[:,0]==0))\n",
        "  return x,y\n",
        "\n",
        "def minSequenceLength(fastas):\n",
        "    minLen = 10000\n",
        "    for i in fastas:\n",
        "        if minLen > len(i[1]):\n",
        "            minLen = len(i[1])\n",
        "    return minLen\n",
        "\n",
        "def CKSAAP(fastas, gap=5, **kw):\n",
        "    if gap < 0:\n",
        "        print('Error: the gap should be equal or greater than zero' + '\\n\\n')\n",
        "        return 0\n",
        "\n",
        "    if minSequenceLength(fastas) < gap+2:\n",
        "        print('Error: all the sequence length should be larger than the (gap value) + 2 = ' + str(gap+2) + '\\n' + 'Current sequence length ='  + str(minSequenceLength(fastas)) + '\\n\\n')\n",
        "        return 0\n",
        "\n",
        "    AA = 'ACDEFGHIKLMNPQRSTVWY'\n",
        "    encodings = []\n",
        "    aaPairs = []\n",
        "    for aa1 in AA:\n",
        "        for aa2 in AA:\n",
        "            aaPairs.append(aa1 + aa2)\n",
        "    header = ['#']\n",
        "    for g in range(gap+1):\n",
        "        for aa in aaPairs:\n",
        "            header.append(aa + '.gap' + str(g))\n",
        "    encodings.append(header)\n",
        "    for i in fastas:\n",
        "        name, sequence = i[0], i[1]\n",
        "        code = [name]\n",
        "        for g in range(gap+1):\n",
        "            myDict = {}\n",
        "            for pair in aaPairs:\n",
        "                myDict[pair] = 0\n",
        "            sum = 0\n",
        "            for index1 in range(len(sequence)):\n",
        "                index2 = index1 + g + 1\n",
        "                if index1 < len(sequence) and index2 < len(sequence) and sequence[index1] in AA and sequence[index2] in AA:\n",
        "                    myDict[sequence[index1] + sequence[index2]] = myDict[sequence[index1] + sequence[index2]] + 1\n",
        "                    sum = sum + 1\n",
        "            for pair in aaPairs:\n",
        "                code.append(myDict[pair] / sum)\n",
        "        encodings.append(code)\n",
        "    return encodings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "0d062756",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d062756",
        "outputId": "91cb4afb-bccd-4b68-8fa2-8ab0842ed9f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num pos: 206 num neg: 138\n",
            "(35, 3600)\n",
            "num pos train: 185 num neg train: 124\n",
            "Fold #  1\n",
            "After Resampling \n",
            " num pos train: 185 num neg train: 186\n",
            "0.9142857142857143 0.9523809523809523 0.8571428571428571 0.9302325581395349 0.8207677342949549 0.9047619047619047 0.8095238095238093\n",
            "(35, 3600)\n",
            "num pos train: 185 num neg train: 124\n",
            "Fold #  2\n",
            "After Resampling \n",
            " num pos train: 185 num neg train: 186\n",
            "0.8857142857142857 0.9523809523809523 0.7857142857142857 0.9090909090909091 0.7617834401336352 0.8690476190476191 0.7380952380952381\n",
            "(35, 3600)\n",
            "num pos train: 185 num neg train: 124\n",
            "Fold #  3\n",
            "After Resampling \n",
            " num pos train: 185 num neg train: 187\n",
            "0.9714285714285714 1.0 0.9285714285714286 0.9767441860465116 0.9414688716912718 0.9642857142857143 0.9285714285714286\n",
            "(35, 3600)\n",
            "num pos train: 185 num neg train: 124\n",
            "Fold #  4\n",
            "After Resampling \n",
            " num pos train: 185 num neg train: 187\n",
            "0.8857142857142857 0.8571428571428571 0.9285714285714286 0.9 0.7726832945548975 0.8928571428571428 0.7857142857142856\n",
            "(34, 3600)\n",
            "num pos train: 186 num neg train: 124\n",
            "Fold #  5\n",
            "After Resampling \n",
            " num pos train: 186 num neg train: 188\n",
            "0.9411764705882353 0.95 0.9285714285714286 0.95 0.8785714285714286 0.9392857142857143 0.8785714285714286\n",
            "(34, 3600)\n",
            "num pos train: 186 num neg train: 124\n",
            "Fold #  6\n",
            "After Resampling \n",
            " num pos train: 186 num neg train: 188\n",
            "0.9117647058823529 0.95 0.8571428571428571 0.926829268292683 0.8174253462889596 0.9035714285714285 0.8071428571428569\n",
            "(34, 3600)\n",
            "num pos train: 186 num neg train: 124\n",
            "Fold #  7\n",
            "After Resampling \n",
            " num pos train: 186 num neg train: 188\n",
            "1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "(34, 3600)\n",
            "num pos train: 186 num neg train: 124\n",
            "Fold #  8\n",
            "After Resampling \n",
            " num pos train: 186 num neg train: 188\n",
            "0.9117647058823529 1.0 0.7857142857142857 0.9302325581395349 0.8265771673985414 0.8928571428571428 0.7857142857142856\n",
            "(34, 3600)\n",
            "num pos train: 185 num neg train: 125\n",
            "Fold #  9\n",
            "After Resampling \n",
            " num pos train: 185 num neg train: 188\n",
            "0.9705882352941176 0.9523809523809523 1.0 0.975609756097561 0.9404008408634048 0.9761904761904762 0.9523809523809523\n",
            "(34, 3600)\n",
            "num pos train: 185 num neg train: 125\n",
            "Fold #  10\n",
            "After Resampling \n",
            " num pos train: 185 num neg train: 187\n",
            "0.8823529411764706 1.0 0.6923076923076923 0.9130434782608695 0.7625866911626911 0.8461538461538461 0.6923076923076923\n",
            "Mean stats: [0.92747899 0.96142857 0.87637363 0.94117827 0.85222648 0.9189011\n",
            " 0.8378022 ]\n",
            "Std stats: [0.03928075 0.04163332 0.0947623  0.03154458 0.07979411 0.04680109\n",
            " 0.09360219]\n"
          ]
        }
      ],
      "source": [
        "  ## Perform Monte-Carlos Simulations for [num_Trials]# of independent Trials\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "# LVs = range(3,4)\n",
        "# num_Trails = 10\n",
        "gaps = 8\n",
        "loop_ind = 0\n",
        "stats = []\n",
        "# kf = KFold(n_splits=10)\n",
        "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=2)\n",
        "# import warnings filter\n",
        "from warnings import simplefilter\n",
        "# ignore all future warnings\n",
        "simplefilter(action='ignore', category=FutureWarning)\n",
        "[DataX, LabelY] = Convert_Seq2CKSAAP(ALL_seq, gap=8)     \n",
        "for train_index, test_index in kf.split(DataX,np.argmax(LabelY,axis=1)):\n",
        "    loop_ind = loop_ind + 1\n",
        "    X_train, X_test = DataX[train_index], DataX[test_index]\n",
        "    y_train, y_test = LabelY[train_index], LabelY[test_index]\n",
        "    print(X_test.shape)\n",
        "    print('num pos train:', sum(y_train[:,0]==1), 'num neg train:', sum(y_train[:,0]==0))\n",
        "    y_train = y_train[:,0]\n",
        "    y_test=y_test[:,0]  \n",
        "\n",
        "    print('Fold # ', loop_ind)\n",
        "    ## pre-processing PCA\n",
        "    normalizer = Normalizer().fit(X_train)  # fit does nothing\n",
        "    X_train = normalizer.transform(X_train)\n",
        "    X_test = normalizer.transform(X_test)\n",
        "    # print('pre-PCA-l2-norm:', np.linalg.norm(X_train[0,:]))\n",
        "    # oversampler = SMOTE(random_state=42)\n",
        "    # oversampler = SVMSMOTE(random_state=42)\n",
        "    oversampler = KMeansSMOTE(random_state=42)\n",
        "    # oversampler = BorderlineSMOTE(random_state=42)\n",
        "    X_train, y_train = oversampler.fit_resample(X_train, y_train)\n",
        "    print('After Resampling \\n','num pos train:', sum(y_train==1), 'num neg train:', sum(y_train==0))\n",
        "\n",
        "    # transformer = KernelPCA(n_components=200, kernel='linear')\n",
        "    transformer = KernelPCA(n_components=35, kernel='linear') # 'linear', 'poly', 'rbf', ‘sigmoid’, ‘cosine’\n",
        "    transformer.fit_transform(X_train)\n",
        "    X_train = transformer.transform(X_train)\n",
        "    X_test = transformer.transform(X_test)\n",
        "    \n",
        "    # X_train, y_train = oversampler.fit_resample(X_train, y_train)\n",
        "    # print('After Resampling in PCA\\n','num pos train:', sum(y_train==1), 'num neg train:', sum(y_train==0))\n",
        "\n",
        "    X_train = np.transpose(X_train)\n",
        "    X_test = np.transpose(X_test)\n",
        "    # print(X_train.shape,X_test.shape)\n",
        "    # print(y_train.shape,y_test.shape)\n",
        "    # print('post-PCA-l2-norm:', np.linalg.norm(X_train[:,0]))\n",
        "\n",
        "    # y_train_pred = Test_SRC(X_train,y_train,X_train,y_train,solver='BP',verbose=0, x0=None, ATinvAAT=None, nnz=None, positive=False, tol=1E-4, niter=100, biter=32)\n",
        "    y_test_pred = Test_SRC(X_train,y_train,X_test,y_test,solver='BP',verbose=0, x0=None, ATinvAAT=None, nnz=None, positive=True, tol=1E-4, niter=100, biter=32)\n",
        "\n",
        "    # tr_acc, tr_sen, tr_spe, tr_f1, tr_mcc, tr_bacc, tr_yi = Calculate_Stats(y_train, y_train_pred)\n",
        "    t_acc, t_sen, t_spe, t_f1, t_mcc, t_bacc, t_yi = Calculate_Stats(y_test,y_test_pred)\n",
        "    # print(tr_acc, tr_sen, tr_spe, tr_f1, tr_mcc, tr_bacc, tr_yi)\n",
        "    print(t_acc, t_sen, t_spe, t_f1, t_mcc, t_bacc, t_yi)\n",
        "\n",
        "    stats.append([t_acc, t_sen, t_spe, t_f1, t_mcc, t_bacc, t_yi])\n",
        "\n",
        "\n",
        "\n",
        "print('Mean stats:', np.mean(stats,axis=0))\n",
        "print('Std stats:', np.std(stats,axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "849703ae",
      "metadata": {
        "id": "849703ae"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}