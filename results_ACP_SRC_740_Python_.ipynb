{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ehtisham-Fazal/ACP_KSRC/blob/main/results_ACP_SRC_740_Python_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ec8db92f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec8db92f",
        "outputId": "72132283-9344-4c32-fb96-0112402faa32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=fb5566bf3f31fa12af60d3d7ae926df90069281e3f87e97fe697b2490e5ac49f\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ],
      "source": [
        "import sys, os, re, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import sample\n",
        "\n",
        "## Models\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, BatchNormalization, Dropout\n",
        "from keras import metrics\n",
        "from keras import optimizers\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "import numpy.linalg as LA\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "## Perfmetrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report, accuracy_score, matthews_corrcoef, balanced_accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.metrics import auc, average_precision_score, precision_recall_curve, roc_curve,roc_auc_score\n",
        "\n",
        "\n",
        "## utilities\n",
        "from matplotlib import pyplot as plt\n",
        "!pip install wget\n",
        "import wget\n",
        "\n",
        "\n",
        "## pre-processing\n",
        "from sklearn.preprocessing import normalize, Normalizer\n",
        "from sklearn.decomposition import KernelPCA\n",
        "from imblearn.over_sampling import ADASYN, SMOTE, SVMSMOTE, KMeansSMOTE, BorderlineSMOTE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "# drive.mount('/content/drive',force_remount=True)\n",
        "drive_path = '/content/drive/MyDrive/data_set_acp/ACP_KSRC_RESULTS/'\n",
        "os.chdir(drive_path)\n",
        "os.getcwd() \n"
      ],
      "metadata": {
        "id": "XNrs57ardLkb",
        "outputId": "8b7fcf56-2c7a-4155-f8dc-ca3e36a3cfd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "XNrs57ardLkb",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/data_set_acp/ACP_KSRC_RESULTS'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0f32eaa9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0f32eaa9",
        "outputId": "9be8498a-2e29-4278-f02b-b08ae411d9c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'acp740.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "file1_path = 'https://raw.githubusercontent.com/NLPrinceton/sparse_recovery/master/solvers.py'\n",
        "wget.download(file1_path, 'solvers.py')\n",
        "from solvers import *\n",
        "\n",
        "dataset_path='http://www.cczubio.top/static/ACP-check/datasets/ACP-DL/acp740.txt'\n",
        "wget.download(dataset_path, 'acp740.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "164cc814",
      "metadata": {
        "id": "164cc814"
      },
      "outputs": [],
      "source": [
        "def prepare_feature_acp740():\n",
        "    path = r\"acp740.txt\"\n",
        "    new_list=[]\n",
        "    seq_list=[]\n",
        "    label = []\n",
        "    lis = []\n",
        "    lx=[]\n",
        "    interaction_pair = {}\n",
        "    RNA_seq_dict = {}\n",
        "    protein_seq_dict = {}\n",
        "    protein_index = 0\n",
        "    with open(path, 'r') as fp:\n",
        "        for line in fp:\n",
        "            if line[0] == '>':\n",
        "                values = line[1:].strip().split('|')\n",
        "                label_temp = values[1]            \n",
        "                proteinName = values[0]\n",
        "                proteinName_1=proteinName.split(\"_\")\n",
        "                new_list.append(proteinName_1[0])   \n",
        "\n",
        "                if label_temp == '1':\n",
        "                    label.append(1)\n",
        "                else:\n",
        "                    label.append(0)\n",
        "            else:\n",
        "                seq = line[:-1]\n",
        "                seq_list.append(seq)\n",
        "        for i, item in enumerate(new_list):\n",
        "            lis.append([item, seq_list[i]])\n",
        "        for i in lis:\n",
        "            if len(i[1])>60:\n",
        "                x=([i[0],i[1][0:60]])\n",
        "                lx.append(x)\n",
        "            else:\n",
        "                lx.append(i)        \n",
        "    return lx \n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6b3c418d",
      "metadata": {
        "id": "6b3c418d"
      },
      "outputs": [],
      "source": [
        "def yoden_index(y, y_pred):\n",
        "  epsilon = 1e-30\n",
        "  tn, fp, fn, tp = confusion_matrix(y, y_pred, labels=[0,1]).ravel()\n",
        "  j = (tp/(tp + fn + epsilon)) + (tn/(tn+fp + epsilon)) - 1\n",
        "  return j\n",
        "\n",
        "def pmeasure(y, y_pred):\n",
        "    epsilon = 1e-30\n",
        "    tn, fp, fn, tp = confusion_matrix(y, y_pred, labels=[0,1]).ravel()\n",
        "    sensitivity = tp / (tp + fn + epsilon)\n",
        "    specificity = tn / (tn + fp + epsilon)\n",
        "    f1score = (2 * tp) / (2 * tp + fp + fn + epsilon)\n",
        "    return ({'Sensitivity': sensitivity, 'Specificity': specificity, 'F1-Score': f1score})\n",
        "    \n",
        "def Calculate_Stats(y_actual,y_pred):\n",
        "  acc = accuracy_score(y_actual, y_pred)\n",
        "  sen = pmeasure(y_actual, y_pred)['Sensitivity']\n",
        "  spe = pmeasure(y_actual, y_pred)['Specificity']\n",
        "  f1 = pmeasure(y_actual, y_pred)['F1-Score']\n",
        "  mcc = matthews_corrcoef(y_actual, y_pred)\n",
        "  bacc = balanced_accuracy_score(y_actual, y_pred)\n",
        "  yi = yoden_index(y_actual, y_pred)\n",
        "  \n",
        "  return acc, sen, spe, f1, mcc, bacc, yi"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S3RpYmwOl1YU"
      },
      "id": "S3RpYmwOl1YU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c392a070",
      "metadata": {
        "id": "c392a070"
      },
      "outputs": [],
      "source": [
        "def Test_SRC(A,delta_y,DATA,LABEL,solver='BP',verbose=0, x0=None, ATinvAAT=None, nnz=None, positive=False, tol=1E-4, niter=100, biter=32):\n",
        "  import time\n",
        "  LABEL_PRED = []\n",
        "  SCORE_PRED=[]\n",
        "  count = 0\n",
        "  time_ellapsed = []\n",
        "  for ind in range(0,DATA.shape[1]):\n",
        "    start_time = time.time()\n",
        "    b = DATA[:,ind]\n",
        "    if(solver=='BP'):     \n",
        "      x = BasisPursuit(A, b, x0=x0, ATinvAAT=ATinvAAT, positive=positive, tol=tol, niter=niter, biter=biter)\n",
        "    elif(solver=='MP'):      \n",
        "      x = MatchingPursuit(A, b, tol=tol, nnz=nnz, positive=positive)\n",
        " \n",
        "    label_out, score_out = delta_rule(A,delta_y,x,b)\n",
        "    time_ellapsed.append(time.time()-start_time)\n",
        "    if (verbose):\n",
        "      check = label_out==LABEL[ind]\n",
        "      if (check):\n",
        "        count = count + 1\n",
        "      accuracy = 100*count/(ind+1)\n",
        "      print(ind+1, count, accuracy, LABEL[ind], label_out, check)\n",
        "    LABEL_PRED.append(label_out)\n",
        "    SCORE_PRED.append(score_out)\n",
        "\n",
        "  return np.array(LABEL_PRED), np.array(SCORE_PRED),np.array(time_ellapsed )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9a0e5eaa",
      "metadata": {
        "id": "9a0e5eaa"
      },
      "outputs": [],
      "source": [
        "def delta_rule(A,delta_y,x,b):\n",
        "  delta1 = 0*x\n",
        "  delta2 = 0*x\n",
        "  delta1[delta_y==1]=x[delta_y==1]\n",
        "  delta2[delta_y==0]=x[delta_y==0]\n",
        "  y1 = np.matmul(A,delta1)\n",
        "  y2 = np.matmul(A,delta2)\n",
        "  r1 = np.linalg.norm(y1-b)\n",
        "  r2 = np.linalg.norm(y2-b)\n",
        "\n",
        "  if(r1<r2):\n",
        "    label = 1\n",
        "  else:\n",
        "    label = 0\n",
        "  score=(r2)/(r1+r2)\n",
        "\n",
        "  return label, score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "21031082",
      "metadata": {
        "id": "21031082"
      },
      "outputs": [],
      "source": [
        "def Convert_Seq2CKSAAP(train_seq, gap=8):\n",
        "  cksaapfea = []\n",
        "  seq_label = []\n",
        "  for sseq in train_seq:\n",
        "    temp= CKSAAP([sseq], gap=8)\n",
        "    cksaapfea.append(temp[1][1:])\n",
        "    seq_label.append(sseq[0])\n",
        "\n",
        "  x = np.array(cksaapfea)\n",
        "  y = np.array(seq_label)\n",
        "  y[y=='ACP']=1\n",
        "  y[y=='non-ACP']=0\n",
        "  y = to_categorical(y)\n",
        "  print('num pos:', sum(y[:,0]==1), 'num neg:', sum(y[:,0]==0))\n",
        "  return x,y\n",
        "\n",
        "def minSequenceLength(fastas):\n",
        "    minLen = 10000\n",
        "    for i in fastas:\n",
        "        if minLen > len(i[1]):\n",
        "            minLen = len(i[1])\n",
        "    return minLen\n",
        "\n",
        "def CKSAAP(fastas, gap=5, **kw):\n",
        "    if gap < 0:\n",
        "        print('Error: the gap should be equal or greater than zero' + '\\n\\n')\n",
        "        return 0\n",
        "\n",
        "    if minSequenceLength(fastas) < gap+2:\n",
        "        print('Error: all the sequence length should be larger than the (gap value) + 2 = ' + str(gap+2) + '\\n' + 'Current sequence length ='  + str(minSequenceLength(fastas)) + '\\n\\n')\n",
        "        return 0\n",
        "\n",
        "    AA = 'ACDEFGHIKLMNPQRSTVWY'\n",
        "    encodings = []\n",
        "    aaPairs = []\n",
        "    for aa1 in AA:\n",
        "        for aa2 in AA:\n",
        "            aaPairs.append(aa1 + aa2)\n",
        "    header = ['#']\n",
        "    for g in range(gap+1):\n",
        "        for aa in aaPairs:\n",
        "            header.append(aa + '.gap' + str(g))\n",
        "    encodings.append(header)\n",
        "    for i in fastas:\n",
        "        name, sequence = i[0], i[1]\n",
        "        code = [name]\n",
        "        for g in range(gap+1):\n",
        "            myDict = {}\n",
        "            for pair in aaPairs:\n",
        "                myDict[pair] = 0\n",
        "            sum = 0\n",
        "            for index1 in range(len(sequence)):\n",
        "                index2 = index1 + g + 1\n",
        "                if index1 < len(sequence) and index2 < len(sequence) and sequence[index1] in AA and sequence[index2] in AA:\n",
        "                    myDict[sequence[index1] + sequence[index2]] = myDict[sequence[index1] + sequence[index2]] + 1\n",
        "                    sum = sum + 1\n",
        "            for pair in aaPairs:\n",
        "                code.append(myDict[pair] / sum)\n",
        "        encodings.append(code)\n",
        "    return encodings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.io import savemat"
      ],
      "metadata": {
        "id": "bzSlxmu3YsOf"
      },
      "id": "bzSlxmu3YsOf",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b4f38620",
      "metadata": {
        "id": "b4f38620",
        "outputId": "287109fd-6467-45a0-d974-15db28ddc7fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num pos: 364 num neg: 376\n",
            "num pos train: 292 num neg train: 300\n",
            "Fold #  0\n",
            "After Resampling \n",
            " num pos train: 302 num neg train: 300\n",
            "0.527027027027027 0.4027777777777778 0.6447368421052632 0.453125 0.048968001121641826 0.5237573099415205 0.047514619883040954 [0.0355773  0.04201031 0.0390985  0.03092694 0.02956772 0.0228138\n",
            " 0.02293754 0.02265668 0.02417779 0.02494073 0.02277398 0.02348113\n",
            " 0.02161646 0.02150249 0.02246904 0.02176261 0.02252007 0.02319121\n",
            " 0.02268457 0.02185774 0.03096557 0.02165365 0.02355719 0.02893019\n",
            " 0.02782393 0.02390885 0.02435446 0.02268982 0.02216673 0.02219343\n",
            " 0.02272701 0.02243972 0.02228045 0.02617502 0.02253127 0.02258873\n",
            " 0.02278876 0.02428079 0.02320743 0.02298641 0.0222187  0.02433085\n",
            " 0.02199435 0.02335072 0.02223587 0.02318168 0.02674723 0.03009796\n",
            " 0.02302074 0.02273035 0.02353668 0.03160238 0.02270174 0.02260303\n",
            " 0.02290249 0.02273512 0.02252436 0.02712202 0.02299762 0.02350473\n",
            " 0.02365303 0.02249289 0.02292895 0.02177691 0.02478218 0.02485609\n",
            " 0.02339816 0.02189374 0.02220392 0.02277803 0.0221746  0.02284765\n",
            " 0.02363229 0.02363181 0.02255201 0.02305007 0.02266645 0.02257013\n",
            " 0.02231669 0.02329016 0.0227139  0.02281475 0.02274704 0.02556014\n",
            " 0.0253613  0.02693963 0.02275133 0.02243757 0.0252471  0.02832532\n",
            " 0.02893043 0.0220325  0.02458072 0.02305722 0.02289152 0.023031\n",
            " 0.0237534  0.023911   0.02408767 0.02395678 0.02357197 0.02424288\n",
            " 0.02376723 0.0233674  0.02352834 0.02407193 0.02689433 0.02583146\n",
            " 0.03002262 0.02512693 0.02360082 0.02204537 0.02276468 0.02284694\n",
            " 0.02222443 0.02216387 0.02243423 0.02417755 0.02283096 0.03403616\n",
            " 0.03644156 0.02398133 0.02508664 0.02599406 0.02809548 0.02722454\n",
            " 0.02646732 0.02655387 0.03448439 0.02822208 0.03691196 0.02688408\n",
            " 0.02797961 0.02591777 0.02479339 0.02400899 0.02365375 0.02361655\n",
            " 0.02395892 0.02512956 0.02319765 0.02321172 0.02406979 0.02879977\n",
            " 0.02361751 0.02369308 0.02354789 0.02343559]\n",
            "num pos train: 291 num neg train: 301\n",
            "Fold #  1\n",
            "After Resampling \n",
            " num pos train: 303 num neg train: 301\n",
            "0.5135135135135135 0.3835616438356164 0.64 0.4375 0.02437669533836882 0.5117808219178082 0.02356164383561632 [0.08783841 0.11314583 0.11469698 0.07989955 0.06895065 0.04540896\n",
            " 0.04742551 0.04884195 0.04520369 0.02288413 0.02224922 0.02600431\n",
            " 0.02460265 0.0243032  0.02409887 0.02406812 0.02454734 0.02463031\n",
            " 0.02298832 0.02276897 0.02430487 0.02388477 0.02377582 0.02344155\n",
            " 0.02617764 0.02324128 0.02362275 0.0226388  0.02292085 0.02307606\n",
            " 0.02466822 0.02296257 0.02316833 0.02300954 0.02317405 0.02381325\n",
            " 0.02345371 0.02538157 0.02822447 0.02400398 0.02380443 0.02464628\n",
            " 0.02424884 0.03016043 0.02655363 0.02401495 0.02276015 0.02284384\n",
            " 0.02377415 0.02600217 0.02326894 0.0248127  0.02243352 0.02282643\n",
            " 0.02266431 0.02608395 0.02299023 0.02323818 0.02326441 0.02357578\n",
            " 0.02278996 0.02325249 0.02312446 0.02368999 0.02414131 0.02251554\n",
            " 0.02405477 0.02298188 0.02294135 0.02269197 0.02508378 0.02209449\n",
            " 0.02246928 0.02266359 0.02271008 0.02355719 0.02306056 0.02321911\n",
            " 0.02418852 0.02423978 0.02440643 0.02304697 0.02379441 0.02340221\n",
            " 0.02742267 0.02349305 0.03362632 0.03045082 0.02577186 0.02353883\n",
            " 0.02410579 0.02385116 0.02296996 0.02312517 0.02326441 0.02241635\n",
            " 0.02306104 0.02117968 0.02161288 0.02099085 0.02228618 0.02233291\n",
            " 0.02265716 0.02188873 0.02213597 0.02187061 0.02165627 0.02167463\n",
            " 0.02518415 0.02573013 0.0250423  0.0235405  0.02373576 0.02367306\n",
            " 0.02287126 0.02241659 0.02329922 0.02339196 0.02292728 0.02314568\n",
            " 0.02434063 0.02532601 0.02412963 0.02277231 0.022084   0.0236547\n",
            " 0.0231297  0.02294087 0.02323508 0.0265727  0.02974319 0.02186584\n",
            " 0.02251554 0.0244391  0.02389932 0.02312326 0.02305388 0.02326751\n",
            " 0.02795291 0.0224812  0.02212477 0.02117205 0.02217722 0.02240968\n",
            " 0.02144599 0.02179027 0.0216608  0.02235222]\n",
            "num pos train: 291 num neg train: 301\n",
            "Fold #  2\n",
            "After Resampling \n",
            " num pos train: 302 num neg train: 301\n",
            "0.5 0.3835616438356164 0.6133333333333333 0.4307692307692308 -0.0031900591486464787 0.49844748858447485 -0.003105022831050297 [0.03685212 0.03677201 0.035779   0.02752042 0.02345848 0.024189\n",
            " 0.02212238 0.02371097 0.02443814 0.02409029 0.02447271 0.02324343\n",
            " 0.02187395 0.02304912 0.02185559 0.02182961 0.02176404 0.02283669\n",
            " 0.02461433 0.02648425 0.02364945 0.02326918 0.02721882 0.03192282\n",
            " 0.02342868 0.02310634 0.02196956 0.02303171 0.02284384 0.02246666\n",
            " 0.02353144 0.02579737 0.02519631 0.02412701 0.02434278 0.02435017\n",
            " 0.02403903 0.02425838 0.02420163 0.02361226 0.02362585 0.02289581\n",
            " 0.0263505  0.02425528 0.02303743 0.0232029  0.02375746 0.02491379\n",
            " 0.02290177 0.0234015  0.02361321 0.02294087 0.02351904 0.02359772\n",
            " 0.02449322 0.02402806 0.02456903 0.02318835 0.02302837 0.02427363\n",
            " 0.02390814 0.027807   0.0226295  0.02356577 0.02334142 0.02517128\n",
            " 0.03063989 0.02294731 0.0237453  0.02287769 0.02349901 0.0229435\n",
            " 0.02796936 0.0246377  0.02334118 0.02360225 0.02408195 0.02325249\n",
            " 0.024261   0.02239203 0.022645   0.02245998 0.02284837 0.02473617\n",
            " 0.02208495 0.02205968 0.02197337 0.02135682 0.02136779 0.02246213\n",
            " 0.02230477 0.0218668  0.02156186 0.02368164 0.02627087 0.02223659\n",
            " 0.02386475 0.0242095  0.02394295 0.02526021 0.02379823 0.02410531\n",
            " 0.02368188 0.02501512 0.02517581 0.0224793  0.02277541 0.02245283\n",
            " 0.02213645 0.03787088 0.03975534 0.0224669  0.02304482 0.02357078\n",
            " 0.02436161 0.02434731 0.02362847 0.02317381 0.02338171 0.02391028\n",
            " 0.02514625 0.02414608 0.0254612  0.02597809 0.02303362 0.02588749\n",
            " 0.02273297 0.02271271 0.02104545 0.02169418 0.02250099 0.02333736\n",
            " 0.02218676 0.02261376 0.02409554 0.02318835 0.02277875 0.02336431\n",
            " 0.02861977 0.02263212 0.02342463 0.02222753 0.02323842 0.02381182\n",
            " 0.02410841 0.02366948 0.02389145 0.02784729]\n",
            "num pos train: 291 num neg train: 301\n",
            "Fold #  3\n",
            "After Resampling \n",
            " num pos train: 303 num neg train: 301\n",
            "0.5067567567567568 0.4246575342465753 0.5866666666666667 0.45925925925925926 0.011475049228876521 0.505662100456621 0.011324200913241933 [0.03810787 0.04272556 0.04049969 0.02453232 0.02505469 0.02446914\n",
            " 0.02476835 0.02506661 0.02704906 0.02767634 0.02790141 0.03447247\n",
            " 0.02538443 0.03196669 0.02927804 0.02437854 0.02413106 0.02395821\n",
            " 0.0237875  0.02305698 0.0229528  0.02961206 0.0232563  0.02636957\n",
            " 0.02498031 0.02688932 0.02470231 0.02498174 0.02416039 0.02624249\n",
            " 0.02425528 0.02356124 0.02455902 0.02539611 0.02367759 0.02306151\n",
            " 0.02300906 0.02572918 0.02460599 0.02498055 0.02626705 0.02562785\n",
            " 0.02472973 0.02434993 0.02431154 0.02499294 0.02404571 0.02402949\n",
            " 0.02405834 0.02429295 0.02801728 0.03308606 0.02307439 0.02386022\n",
            " 0.02517319 0.02278638 0.02307487 0.02234674 0.0228157  0.02318788\n",
            " 0.02297902 0.0224998  0.02692866 0.02405405 0.02234268 0.02506971\n",
            " 0.02354455 0.02347088 0.02334476 0.0235343  0.02207661 0.02343464\n",
            " 0.0271287  0.02476215 0.02465534 0.02481031 0.02416539 0.0239222\n",
            " 0.02486444 0.02307868 0.02428818 0.02304959 0.02362084 0.0262537\n",
            " 0.02300024 0.02225327 0.02191448 0.02216911 0.02518392 0.02246833\n",
            " 0.02466035 0.02322054 0.02375555 0.02604103 0.03081536 0.02348661\n",
            " 0.02425528 0.02353311 0.02370024 0.02372575 0.02449775 0.02343106\n",
            " 0.02365756 0.02403069 0.02290702 0.02276659 0.02152395 0.02534914\n",
            " 0.02244401 0.02332735 0.02580261 0.02656698 0.02939582 0.02326155\n",
            " 0.02388453 0.02380729 0.02449989 0.02350307 0.02201343 0.02325368\n",
            " 0.02215457 0.02206111 0.02257204 0.02148795 0.02329588 0.02338934\n",
            " 0.02348733 0.02241445 0.02256608 0.02265716 0.02277589 0.02223587\n",
            " 0.02234936 0.02194118 0.022367   0.02284551 0.02269983 0.03171802\n",
            " 0.02978969 0.02436209 0.022892   0.02278733 0.0226388  0.02260637\n",
            " 0.02219677 0.02311492 0.02171993 0.02296114]\n",
            "num pos train: 291 num neg train: 301\n",
            "Fold #  4\n",
            "After Resampling \n",
            " num pos train: 303 num neg train: 301\n",
            "0.5202702702702703 0.4383561643835616 0.6 0.4740740740740741 0.03886710222683983 0.5191780821917809 0.03835616438356171 [0.03626752 0.03640056 0.03528523 0.02965856 0.02395296 0.02265286\n",
            " 0.02669859 0.02283955 0.0230267  0.02271032 0.02366257 0.0238719\n",
            " 0.02528238 0.02401042 0.02424669 0.02326322 0.02421308 0.02319312\n",
            " 0.02350473 0.02451777 0.02289009 0.03105927 0.02320504 0.02412248\n",
            " 0.02359056 0.0230298  0.02316594 0.02362871 0.02335596 0.02880979\n",
            " 0.02285051 0.02290893 0.02251601 0.02300811 0.02215409 0.0218792\n",
            " 0.02292204 0.03372717 0.02379918 0.02336454 0.02342129 0.0242095\n",
            " 0.0239048  0.02445245 0.02346468 0.02379012 0.02423096 0.02592731\n",
            " 0.02289605 0.02328491 0.02285862 0.02325082 0.02341104 0.02424216\n",
            " 0.02675843 0.0238533  0.02433705 0.02327275 0.02436829 0.0243876\n",
            " 0.02540445 0.0235548  0.02451468 0.02304482 0.02371192 0.02424669\n",
            " 0.02319932 0.02334642 0.02342963 0.02316451 0.02364731 0.02290583\n",
            " 0.02371335 0.02416873 0.02280855 0.02301049 0.02336121 0.02259278\n",
            " 0.02322316 0.03322744 0.02775383 0.02334237 0.02272964 0.02347279\n",
            " 0.02271128 0.02368474 0.0237267  0.02270484 0.02286696 0.02501321\n",
            " 0.02286792 0.02308321 0.02281857 0.02205324 0.02262735 0.02335238\n",
            " 0.02173686 0.02228379 0.02279353 0.02259088 0.02235317 0.0216012\n",
            " 0.0260644  0.02276564 0.02229691 0.02394962 0.02151489 0.02322507\n",
            " 0.0231998  0.02303147 0.02283072 0.02334762 0.02333927 0.02355981\n",
            " 0.02278376 0.02273417 0.02345395 0.02243876 0.02686167 0.02183175\n",
            " 0.02333736 0.02393317 0.02297902 0.03054619 0.0223918  0.02183938\n",
            " 0.0217483  0.02212358 0.02129006 0.02182436 0.02182674 0.02280712\n",
            " 0.02388334 0.02404547 0.02319241 0.02668738 0.0219779  0.02337742\n",
            " 0.02313495 0.0222559  0.02325249 0.02336478 0.02238631 0.02305913\n",
            " 0.02716851 0.02339888 0.0282824  0.02378678]\n",
            "SAVING... ACP_KSRC_STATS_CKSAAP_GAP8_PC10.mat\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num pos: 364 num neg: 376\n",
            "num pos train: 292 num neg train: 300\n",
            "Fold #  0\n",
            "After Resampling \n",
            " num pos train: 302 num neg train: 300\n",
            "0.7837837837837838 0.75 0.8157894736842105 0.7714285714285715 0.5674511203564657 0.7828947368421053 0.5657894736842106 [0.17642736 0.11015916 0.10733724 0.15520668 0.11939001 0.12055707\n",
            " 0.1973877  0.14837766 0.12766886 0.1586616  0.15390515 0.14700842\n",
            " 0.19431424 0.15511346 0.10239124 0.09583378 0.11638284 0.09586978\n",
            " 0.14009047 0.16433597 0.14075565 0.13766909 0.11422491 0.07876039\n",
            " 0.05451989 0.049335   0.0489881  0.05180573 0.05233359 0.0703969\n",
            " 0.04366446 0.0421946  0.0437746  0.04431391 0.04947114 0.04485035\n",
            " 0.04367518 0.04509497 0.04405522 0.04347157 0.04360342 0.04938555\n",
            " 0.04545236 0.04429674 0.04608202 0.04684567 0.04338741 0.0417192\n",
            " 0.04312444 0.0435071  0.04238009 0.04572105 0.06727004 0.04619479\n",
            " 0.04682899 0.04789448 0.04623556 0.04918122 0.04907823 0.04846835\n",
            " 0.04735112 0.04704499 0.04626703 0.04572892 0.04405236 0.04317021\n",
            " 0.04247999 0.05003619 0.04335332 0.04301476 0.04034209 0.04025936\n",
            " 0.0441339  0.04327798 0.05896997 0.04289389 0.04271364 0.04215503\n",
            " 0.04231143 0.04796982 0.0443325  0.0448916  0.04437208 0.04481292\n",
            " 0.0425024  0.04338455 0.04183722 0.04765725 0.04459    0.04458094\n",
            " 0.04503489 0.04465961 0.04450583 0.04230881 0.04501724 0.04297805\n",
            " 0.04249334 0.06001306 0.04870605 0.0438199  0.04465675 0.04465055\n",
            " 0.04501987 0.04701829 0.04233956 0.04060555 0.04113412 0.0462532\n",
            " 0.04132652 0.04150701 0.04135323 0.04597878 0.04694057 0.04572797\n",
            " 0.04481745 0.04443264 0.04294324 0.04409289 0.04156685 0.05010295\n",
            " 0.0508132  0.04719877 0.04269385 0.04463291 0.04377937 0.04368067\n",
            " 0.04320097 0.04094648 0.04125381 0.04095554 0.0416882  0.04293394\n",
            " 0.04180193 0.04402995 0.05292702 0.04607296 0.06636596 0.04461503\n",
            " 0.04362798 0.04623055 0.04295039 0.04334164 0.06445265 0.04486108\n",
            " 0.04206085 0.04614162 0.04209638 0.04210353]\n",
            "num pos train: 291 num neg train: 301\n",
            "Fold #  1\n",
            "After Resampling \n",
            " num pos train: 303 num neg train: 301\n",
            "0.7364864864864865 0.7671232876712328 0.7066666666666667 0.7417218543046358 0.47444031834252676 0.7368949771689497 0.4737899543378994 [0.04882956 0.04432464 0.04651499 0.04512453 0.04589772 0.04480457\n",
            " 0.04486012 0.04518223 0.05235934 0.04367208 0.04317665 0.04013991\n",
            " 0.04242277 0.04203176 0.04354334 0.04527831 0.04614639 0.04488277\n",
            " 0.05104446 0.07552981 0.04469132 0.05920815 0.04366183 0.04427099\n",
            " 0.04711246 0.0410049  0.04309034 0.04373574 0.04328942 0.04281497\n",
            " 0.04296517 0.04437232 0.0461762  0.04536343 0.05100656 0.0453105\n",
            " 0.04477859 0.04486084 0.04366088 0.04466414 0.04211593 0.04136777\n",
            " 0.0423491  0.04275346 0.06184053 0.04486442 0.04663777 0.04498291\n",
            " 0.04967761 0.04272842 0.04337978 0.04308987 0.04414201 0.043262\n",
            " 0.04769659 0.0452342  0.04464889 0.0445931  0.04569459 0.04528546\n",
            " 0.0432539  0.04380059 0.0411334  0.04240847 0.04391623 0.0421679\n",
            " 0.064363   0.04410648 0.04477119 0.04343748 0.04609132 0.0444181\n",
            " 0.0431633  0.04299307 0.0475204  0.04247332 0.0421052  0.04292655\n",
            " 0.04182506 0.04332304 0.04353786 0.04324341 0.04464793 0.0454731\n",
            " 0.04868293 0.04368472 0.04164529 0.04012418 0.0413065  0.06040311\n",
            " 0.04598427 0.04350162 0.04545689 0.04506254 0.04382896 0.0439961\n",
            " 0.0416975  0.04208589 0.0509367  0.04353952 0.04512095 0.05218959\n",
            " 0.04605412 0.04378319 0.04428172 0.04291081 0.04674172 0.04220223\n",
            " 0.04200244 0.04253936 0.04230952 0.04334354 0.06454492 0.04280543\n",
            " 0.04266715 0.04248834 0.04295516 0.04541016 0.04552412 0.04663968\n",
            " 0.04670167 0.04857707 0.04498386 0.04910612 0.04390669 0.04371023\n",
            " 0.04510117 0.043751   0.047364   0.04411268 0.04497719 0.04355812\n",
            " 0.04362178 0.04435921 0.05982256 0.0439291  0.04387832 0.04482341\n",
            " 0.04783058 0.05158496 0.05110431 0.04355764 0.04503226 0.04531956\n",
            " 0.04626393 0.04545927 0.04388428 0.04388952]\n",
            "num pos train: 291 num neg train: 301\n",
            "Fold #  2\n",
            "After Resampling \n",
            " num pos train: 302 num neg train: 301\n",
            "0.7905405405405406 0.8767123287671232 0.7066666666666667 0.8050314465408805 0.5911501167263162 0.7916894977168949 0.5833789954337898 [0.04523301 0.04527473 0.05188417 0.04316783 0.04282212 0.04079986\n",
            " 0.04389596 0.04238534 0.04094195 0.04104805 0.04212785 0.04326701\n",
            " 0.04338479 0.06546259 0.04332185 0.0426228  0.04164362 0.04174209\n",
            " 0.04305267 0.04135489 0.04230213 0.04585004 0.04215503 0.0420177\n",
            " 0.04380751 0.04281092 0.04331732 0.04102087 0.04243803 0.06028843\n",
            " 0.040905   0.04119921 0.04506636 0.04480076 0.04288936 0.04272699\n",
            " 0.05750442 0.04413342 0.04319477 0.04191589 0.0413878  0.04209495\n",
            " 0.0469234  0.04722929 0.04649115 0.04849935 0.04808807 0.05166268\n",
            " 0.04671693 0.04445529 0.04668236 0.0452311  0.04643869 0.04607868\n",
            " 0.04515266 0.04585052 0.04598475 0.04697514 0.05906749 0.04597425\n",
            " 0.04540205 0.04629946 0.04495907 0.0458889  0.04725146 0.04683232\n",
            " 0.04261661 0.04699445 0.04283857 0.04311013 0.04310966 0.04271126\n",
            " 0.04413414 0.04268217 0.04520035 0.04346228 0.04295278 0.04392004\n",
            " 0.0434351  0.04714084 0.05674934 0.04475474 0.04305959 0.04320693\n",
            " 0.04293633 0.04284835 0.04367423 0.04347253 0.04864383 0.04666615\n",
            " 0.04487062 0.04487967 0.04469943 0.04627395 0.04574871 0.04237437\n",
            " 0.04316092 0.04239154 0.04202938 0.04340482 0.04908156 0.04398751\n",
            " 0.04319501 0.06187224 0.05883002 0.04421663 0.04292536 0.05192709\n",
            " 0.04689574 0.04712868 0.04680681 0.04371071 0.04457426 0.04437041\n",
            " 0.04605055 0.04570746 0.0474577  0.04333091 0.04502678 0.04355526\n",
            " 0.04221344 0.04533076 0.04958391 0.0442884  0.04320216 0.06276941\n",
            " 0.04860997 0.04780221 0.04528737 0.04610181 0.04402995 0.04451799\n",
            " 0.04606462 0.06233525 0.05092263 0.04628849 0.04695702 0.05398893\n",
            " 0.04809618 0.04511666 0.04074621 0.04144144 0.04190898 0.04289961\n",
            " 0.04234171 0.04555488 0.04425883 0.06129003]\n",
            "num pos train: 291 num neg train: 301\n",
            "Fold #  3\n",
            "After Resampling \n",
            " num pos train: 303 num neg train: 301\n",
            "0.7567567567567568 0.821917808219178 0.6933333333333334 0.7692307692307693 0.519057295899261 0.7576255707762557 0.5152511415525114 [0.04667735 0.04544806 0.04395318 0.04008293 0.05083513 0.05900431\n",
            " 0.04131079 0.04015875 0.04693222 0.04047751 0.04182434 0.05444956\n",
            " 0.04616857 0.04640675 0.04269838 0.04349494 0.04218602 0.04365277\n",
            " 0.04365873 0.04718494 0.0419817  0.04250836 0.04300237 0.04142809\n",
            " 0.04382777 0.0413487  0.04317141 0.0439961  0.05903149 0.04380488\n",
            " 0.04181504 0.04222846 0.04282403 0.04395151 0.04496264 0.04166412\n",
            " 0.03959441 0.04148054 0.04143786 0.04091311 0.04442573 0.04185343\n",
            " 0.04223776 0.0438571  0.04108977 0.04745221 0.04139686 0.04237938\n",
            " 0.0407598  0.04283047 0.04216218 0.04927921 0.04851627 0.04019165\n",
            " 0.04177856 0.04094172 0.04721117 0.04187989 0.04254651 0.04406786\n",
            " 0.04228878 0.04297161 0.04226971 0.04482079 0.0400908  0.04060745\n",
            " 0.04177856 0.04090786 0.04588366 0.0410614  0.04407096 0.04284739\n",
            " 0.04114747 0.04290962 0.04150057 0.05804634 0.04189277 0.04683375\n",
            " 0.04371881 0.04362679 0.04652929 0.04329205 0.04344893 0.04304361\n",
            " 0.04336572 0.04369402 0.04668164 0.04453754 0.04516983 0.04427981\n",
            " 0.04819679 0.04373956 0.04369545 0.04162121 0.04186773 0.04641867\n",
            " 0.04474688 0.0862174  0.04120779 0.04389119 0.04474831 0.04588389\n",
            " 0.04642534 0.04204607 0.04274511 0.0433898  0.04345274 0.04720283\n",
            " 0.04583287 0.04363012 0.0445888  0.0439496  0.04433012 0.04329348\n",
            " 0.0432744  0.04231358 0.04340792 0.04632711 0.04349661 0.04415798\n",
            " 0.06005883 0.04472733 0.04458237 0.05008674 0.04523754 0.04579616\n",
            " 0.04557467 0.04491806 0.04516768 0.04717159 0.04620194 0.0445838\n",
            " 0.04618835 0.04331541 0.04338527 0.04484868 0.04596376 0.04434609\n",
            " 0.04427266 0.04750514 0.04990315 0.04431701 0.06047845 0.04567742\n",
            " 0.04775953 0.04314137 0.04312277 0.04216671]\n",
            "num pos train: 291 num neg train: 301\n",
            "Fold #  4\n",
            "After Resampling \n",
            " num pos train: 303 num neg train: 301\n",
            "0.7837837837837838 0.8082191780821918 0.76 0.7866666666666666 0.5686347708809082 0.7841095890410958 0.5682191780821917 [0.04563618 0.04262352 0.0415144  0.04081893 0.04093742 0.04151797\n",
            " 0.04329753 0.04146266 0.04096341 0.04377222 0.04319    0.04486871\n",
            " 0.04608679 0.05184484 0.04329348 0.04433084 0.04324627 0.04362035\n",
            " 0.04340672 0.04364944 0.0617795  0.04415131 0.05058217 0.04630446\n",
            " 0.04327846 0.04199195 0.04360151 0.04195309 0.04275346 0.04047275\n",
            " 0.04040575 0.04151011 0.04250813 0.04207087 0.04665589 0.04285669\n",
            " 0.04246545 0.04294491 0.04440093 0.04230499 0.04449368 0.04372621\n",
            " 0.04295373 0.063658   0.04229021 0.04432535 0.04278111 0.04396272\n",
            " 0.04201102 0.04430151 0.0446558  0.04660535 0.04357553 0.04332829\n",
            " 0.04478002 0.04396129 0.04438019 0.04550266 0.04543018 0.04649162\n",
            " 0.04823017 0.04957032 0.04891419 0.04347014 0.04311109 0.04185176\n",
            " 0.0594511  0.04266095 0.04019308 0.04119205 0.04878974 0.04305959\n",
            " 0.04206824 0.04418921 0.04969144 0.04444075 0.04493618 0.0440352\n",
            " 0.04563403 0.04550076 0.04596424 0.04509115 0.04738998 0.0460732\n",
            " 0.04450631 0.04467964 0.04709673 0.04553819 0.05857921 0.04799271\n",
            " 0.04261827 0.04253697 0.04239321 0.04355025 0.04017377 0.04286838\n",
            " 0.04277754 0.04507303 0.04871416 0.0474596  0.04744959 0.04728818\n",
            " 0.04363346 0.04270387 0.04508853 0.04040003 0.0464139  0.04083061\n",
            " 0.04047513 0.04579091 0.04373097 0.06059575 0.04304934 0.04398417\n",
            " 0.04351258 0.04253268 0.04347515 0.04567862 0.04402208 0.0443821\n",
            " 0.04416132 0.0461638  0.04497719 0.04392004 0.04351449 0.04220009\n",
            " 0.04338717 0.04417872 0.04322124 0.04863429 0.0428555  0.04405451\n",
            " 0.06495023 0.05705738 0.04227734 0.04391289 0.04432726 0.04251289\n",
            " 0.04345918 0.04586077 0.04180002 0.04025245 0.04241371 0.04122758\n",
            " 0.04067683 0.04228258 0.04214287 0.04116058]\n",
            "SAVING... ACP_KSRC_STATS_CKSAAP_GAP8_PC20.mat\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "gaps = 8\n",
        "classification_time=[]\n",
        "cross_fold_ing = 0\n",
        "# pc_list=[10,20,30,40,50,60,70,80,90,100,110,150,175,200,225,250,300,350,400,450,500,550,600]\n",
        "pc_list=[10,20]\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
        "# import warnings filter\n",
        "from warnings import simplefilter\n",
        "# ignore all future warnings\n",
        "simplefilter(action='ignore', category=FutureWarning)\n",
        "for num_pc  in pc_list:\n",
        "  stats = []\n",
        "  cross_fold_ing=-1\n",
        "  [DataX, LabelY] = Convert_Seq2CKSAAP(prepare_feature_acp740(), gap=8)     \n",
        "  for train_index, test_index in kf.split(DataX,np.argmax(LabelY,axis=1)):\n",
        "      cross_fold_ing = cross_fold_ing + 1\n",
        "      X_train, X_test = DataX[train_index], DataX[test_index]\n",
        "      y_train, y_test = LabelY[train_index], LabelY[test_index]\n",
        "      print('num pos train:', sum(y_train[:,0]==1), 'num neg train:', sum(y_train[:,0]==0))\n",
        "      y_train = y_train[:,0]\n",
        "      y_test=y_test[:,0]  \n",
        "\n",
        "      print('Fold # ', cross_fold_ing)\n",
        "      ## pre-processing PCA\n",
        "      normalizer = Normalizer().fit(X_train)  \n",
        "      X_train = normalizer.transform(X_train)\n",
        "      X_test = normalizer.transform(X_test)\n",
        "      oversampler = KMeansSMOTE(random_state=42)    \n",
        "      X_train, y_train = oversampler.fit_resample(X_train, y_train)\n",
        "      print('After Resampling \\n','num pos train:', sum(y_train==1), 'num neg train:', sum(y_train==0))\n",
        "      transformer = KernelPCA(n_components=num_pc, kernel='poly') # 'linear', 'poly', 'rbf', sigmoid, cosine\n",
        "      transformer.fit_transform(X_train)\n",
        "      X_train = transformer.transform(X_train)\n",
        "      X_test = transformer.transform(X_test)  \n",
        "      X_train = np.transpose(X_train)\n",
        "      X_test = np.transpose(X_test)\n",
        "      y_test_pred,y_test_score,elp_time= Test_SRC(X_train,y_train,X_test,y_test,solver='BP',verbose=0, x0=None, ATinvAAT=None, nnz=None, positive=True, tol=1E-4, niter=100, biter=32)\n",
        "\n",
        "      # tr_acc, tr_sen, tr_spe, tr_f1, tr_mcc, tr_bacc, tr_yi = Calculate_Stats(y_train, y_train_pred)\n",
        "      t_acc, t_sen, t_spe, t_f1, t_mcc, t_bacc, t_yi = Calculate_Stats(y_test,y_test_pred)\n",
        "      \n",
        "      print(t_acc, t_sen, t_spe, t_f1, t_mcc, t_bacc, t_yi, elp_time)\n",
        "\n",
        "      stats.append([t_acc, t_sen, t_spe, t_f1, t_mcc, t_bacc, t_yi])\n",
        "      classification_time.append(elp_time)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # print('Mean stats:', np.mean(stats,axis=0))\n",
        "  # print('Mean stats:', np.mean(classification_time,axis=0))\n",
        "  # print('Std stats:', np.std(stats,axis=0))\n",
        "  x=np.mean(stats,axis=0)\n",
        "  # print(\"B_ACC={}, MCC={}, Youden's_index={}\".format(x[5],x[4],x[6]))\n",
        "  ###AUC ROC CURVE\n",
        "  r_auc = roc_auc_score(y_test,y_test_score)\n",
        "  r_fpr, r_tpr, _ = roc_curve(y_test,y_test_score)\n",
        "  plt.plot(r_fpr, r_tpr, linestyle='--', label='ACP_SRC (AUROC = %0.3f)' % r_auc)\n",
        "  # del model  # deletes the existing model\n",
        "  Class_Statistics = np.asarray(stats)\n",
        "  Time_Statistics= np.asarray(classification_time)\n",
        "  filename = 'ACP_KSRC_STATS_CKSAAP_GAP' + str(gaps) + '_PC' + str(num_pc) + '.mat'\n",
        "  savemat(filename,{'Class_Statistics':Class_Statistics},{'Time_Statistics':Time_Statistics})\n",
        "  print('SAVING... '+ filename)\n",
        "\n",
        "  # Title\n",
        "  # plt.title('ROC Plot')\n",
        "  # # Axis labels\n",
        "  # plt.xlabel('False Positive Rate')\n",
        "  # plt.ylabel('True Positive Rate')\n",
        "  # Show legend\n",
        "  plt.legend() # \n",
        "  # Show plot\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "savemat(filename,{'Class_Statistics':Class_Statistics,'Time_Statistics':Time_Statistics})"
      ],
      "metadata": {
        "id": "8ZEZ9TOQaRVR"
      },
      "id": "8ZEZ9TOQaRVR",
      "execution_count": 25,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}