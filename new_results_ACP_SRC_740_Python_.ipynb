{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ehtisham-Fazal/ACP_KSRC/blob/main/new_results_ACP_SRC_740_Python_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec8db92f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec8db92f",
        "outputId": "5b2c3de3-8c70-4c50-bab1-6d58b02e8388"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n"
          ]
        }
      ],
      "source": [
        "import sys, os, re, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import sample\n",
        "\n",
        "## Models\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, BatchNormalization, Dropout\n",
        "from keras import metrics\n",
        "from keras import optimizers\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "import numpy.linalg as LA\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "## Perfmetrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report, accuracy_score, matthews_corrcoef, balanced_accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.metrics import auc, average_precision_score, precision_recall_curve, roc_curve,roc_auc_score\n",
        "\n",
        "\n",
        "## utilities\n",
        "from matplotlib import pyplot as plt\n",
        "!pip install wget\n",
        "import wget\n",
        "\n",
        "\n",
        "## pre-processing\n",
        "from sklearn.preprocessing import normalize, Normalizer\n",
        "from sklearn.decomposition import KernelPCA\n",
        "from imblearn.over_sampling import ADASYN, SMOTE, SVMSMOTE, KMeansSMOTE, BorderlineSMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f32eaa9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0f32eaa9",
        "outputId": "d7d1f907-0711-4847-dad3-8f1ebb032b3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'acp740.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "file1_path = 'https://raw.githubusercontent.com/NLPrinceton/sparse_recovery/master/solvers.py'\n",
        "wget.download(file1_path, 'solvers.py')\n",
        "from solvers import *\n",
        "\n",
        "dataset_path='http://www.cczubio.top/static/ACP-check/datasets/ACP-DL/acp740.txt'\n",
        "wget.download(dataset_path, 'acp740.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "164cc814",
      "metadata": {
        "id": "164cc814"
      },
      "outputs": [],
      "source": [
        "def prepare_feature_acp740():\n",
        "    path = r\"acp740.txt\"\n",
        "    new_list=[]\n",
        "    seq_list=[]\n",
        "    label = []\n",
        "    lis = []\n",
        "    lx=[]\n",
        "    interaction_pair = {}\n",
        "    RNA_seq_dict = {}\n",
        "    protein_seq_dict = {}\n",
        "    protein_index = 0\n",
        "    with open(path, 'r') as fp:\n",
        "        for line in fp:\n",
        "            if line[0] == '>':\n",
        "                values = line[1:].strip().split('|')\n",
        "                label_temp = values[1]            \n",
        "                proteinName = values[0]\n",
        "                proteinName_1=proteinName.split(\"_\")\n",
        "                new_list.append(proteinName_1[0])   \n",
        "\n",
        "                if label_temp == '1':\n",
        "                    label.append(1)\n",
        "                else:\n",
        "                    label.append(0)\n",
        "            else:\n",
        "                seq = line[:-1]\n",
        "                seq_list.append(seq)\n",
        "        for i, item in enumerate(new_list):\n",
        "            lis.append([item, seq_list[i]])\n",
        "        for i in lis:\n",
        "            if len(i[1])>60:\n",
        "                x=([i[0],i[1][0:60]])\n",
        "                lx.append(x)\n",
        "            else:\n",
        "                lx.append(i)        \n",
        "    return lx \n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b3c418d",
      "metadata": {
        "id": "6b3c418d"
      },
      "outputs": [],
      "source": [
        "def yoden_index(y, y_pred):\n",
        "  epsilon = 1e-30\n",
        "  tn, fp, fn, tp = confusion_matrix(y, y_pred, labels=[0,1]).ravel()\n",
        "  j = (tp/(tp + fn + epsilon)) + (tn/(tn+fp + epsilon)) - 1\n",
        "  return j\n",
        "\n",
        "def pmeasure(y, y_pred):\n",
        "    epsilon = 1e-30\n",
        "    tn, fp, fn, tp = confusion_matrix(y, y_pred, labels=[0,1]).ravel()\n",
        "    sensitivity = tp / (tp + fn + epsilon)\n",
        "    specificity = tn / (tn + fp + epsilon)\n",
        "    f1score = (2 * tp) / (2 * tp + fp + fn + epsilon)\n",
        "    return ({'Sensitivity': sensitivity, 'Specificity': specificity, 'F1-Score': f1score})\n",
        "    \n",
        "def Calculate_Stats(y_actual,y_pred):\n",
        "  acc = accuracy_score(y_actual, y_pred)\n",
        "  sen = pmeasure(y_actual, y_pred)['Sensitivity']\n",
        "  spe = pmeasure(y_actual, y_pred)['Specificity']\n",
        "  f1 = pmeasure(y_actual, y_pred)['F1-Score']\n",
        "  mcc = matthews_corrcoef(y_actual, y_pred)\n",
        "  bacc = balanced_accuracy_score(y_actual, y_pred)\n",
        "  yi = yoden_index(y_actual, y_pred)\n",
        "  \n",
        "  return acc, sen, spe, f1, mcc, bacc, yi"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S3RpYmwOl1YU"
      },
      "id": "S3RpYmwOl1YU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c392a070",
      "metadata": {
        "id": "c392a070"
      },
      "outputs": [],
      "source": [
        "def Test_SRC(A,delta_y,DATA,LABEL,solver='BP',verbose=0, x0=None, ATinvAAT=None, nnz=None, positive=False, tol=1E-4, niter=100, biter=32):\n",
        "  import time\n",
        "  LABEL_PRED = []\n",
        "  SCORE_PRED=[]\n",
        "  count = 0\n",
        "  time_ellapsed = []\n",
        "  for ind in range(0,DATA.shape[1]):\n",
        "    start_time = time.time()\n",
        "    b = DATA[:,ind]\n",
        "    if(solver=='BP'):     \n",
        "      x = BasisPursuit(A, b, x0=x0, ATinvAAT=ATinvAAT, positive=positive, tol=tol, niter=niter, biter=biter)\n",
        "    elif(solver=='MP'):      \n",
        "      x = MatchingPursuit(A, b, tol=tol, nnz=nnz, positive=positive)\n",
        " \n",
        "    label_out, score_out = delta_rule(A,delta_y,x,b)\n",
        "    time_ellapsed.append(time.time()-start_time)\n",
        "    if (verbose):\n",
        "      check = label_out==LABEL[ind]\n",
        "      if (check):\n",
        "        count = count + 1\n",
        "      accuracy = 100*count/(ind+1)\n",
        "      print(ind+1, count, accuracy, LABEL[ind], label_out, check)\n",
        "    LABEL_PRED.append(label_out)\n",
        "    SCORE_PRED.append(score_out)\n",
        "\n",
        "  return np.array(LABEL_PRED), np.array(SCORE_PRED),np.array(time_ellapsed )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a0e5eaa",
      "metadata": {
        "id": "9a0e5eaa"
      },
      "outputs": [],
      "source": [
        "def delta_rule(A,delta_y,x,b):\n",
        "  delta1 = 0*x\n",
        "  delta2 = 0*x\n",
        "  delta1[delta_y==1]=x[delta_y==1]\n",
        "  delta2[delta_y==0]=x[delta_y==0]\n",
        "  y1 = np.matmul(A,delta1)\n",
        "  y2 = np.matmul(A,delta2)\n",
        "  r1 = np.linalg.norm(y1-b)\n",
        "  r2 = np.linalg.norm(y2-b)\n",
        "\n",
        "  if(r1<r2):\n",
        "    label = 1\n",
        "  else:\n",
        "    label = 0\n",
        "  score=(r2)/(r1+r2)\n",
        "\n",
        "  return label, score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21031082",
      "metadata": {
        "id": "21031082"
      },
      "outputs": [],
      "source": [
        "def Convert_Seq2CKSAAP(train_seq, gap=8):\n",
        "  cksaapfea = []\n",
        "  seq_label = []\n",
        "  for sseq in train_seq:\n",
        "    temp= CKSAAP([sseq], gap=8)\n",
        "    cksaapfea.append(temp[1][1:])\n",
        "    seq_label.append(sseq[0])\n",
        "\n",
        "  x = np.array(cksaapfea)\n",
        "  y = np.array(seq_label)\n",
        "  y[y=='ACP']=1\n",
        "  y[y=='non-ACP']=0\n",
        "  y = to_categorical(y)\n",
        "  print('num pos:', sum(y[:,0]==1), 'num neg:', sum(y[:,0]==0))\n",
        "  return x,y\n",
        "\n",
        "def minSequenceLength(fastas):\n",
        "    minLen = 10000\n",
        "    for i in fastas:\n",
        "        if minLen > len(i[1]):\n",
        "            minLen = len(i[1])\n",
        "    return minLen\n",
        "\n",
        "def CKSAAP(fastas, gap=5, **kw):\n",
        "    if gap < 0:\n",
        "        print('Error: the gap should be equal or greater than zero' + '\\n\\n')\n",
        "        return 0\n",
        "\n",
        "    if minSequenceLength(fastas) < gap+2:\n",
        "        print('Error: all the sequence length should be larger than the (gap value) + 2 = ' + str(gap+2) + '\\n' + 'Current sequence length ='  + str(minSequenceLength(fastas)) + '\\n\\n')\n",
        "        return 0\n",
        "\n",
        "    AA = 'ACDEFGHIKLMNPQRSTVWY'\n",
        "    encodings = []\n",
        "    aaPairs = []\n",
        "    for aa1 in AA:\n",
        "        for aa2 in AA:\n",
        "            aaPairs.append(aa1 + aa2)\n",
        "    header = ['#']\n",
        "    for g in range(gap+1):\n",
        "        for aa in aaPairs:\n",
        "            header.append(aa + '.gap' + str(g))\n",
        "    encodings.append(header)\n",
        "    for i in fastas:\n",
        "        name, sequence = i[0], i[1]\n",
        "        code = [name]\n",
        "        for g in range(gap+1):\n",
        "            myDict = {}\n",
        "            for pair in aaPairs:\n",
        "                myDict[pair] = 0\n",
        "            sum = 0\n",
        "            for index1 in range(len(sequence)):\n",
        "                index2 = index1 + g + 1\n",
        "                if index1 < len(sequence) and index2 < len(sequence) and sequence[index1] in AA and sequence[index2] in AA:\n",
        "                    myDict[sequence[index1] + sequence[index2]] = myDict[sequence[index1] + sequence[index2]] + 1\n",
        "                    sum = sum + 1\n",
        "            for pair in aaPairs:\n",
        "                code.append(myDict[pair] / sum)\n",
        "        encodings.append(code)\n",
        "    return encodings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4f38620",
      "metadata": {
        "id": "b4f38620",
        "outputId": "322dda19-19b0-4252-9bdb-3761945bb17a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num pos: 364 num neg: 376\n",
            "num pos train: 292 num neg train: 300\n",
            "num pos train: 291 num neg train: 301\n",
            "num pos train: 291 num neg train: 301\n",
            "num pos train: 291 num neg train: 301\n",
            "num pos train: 291 num neg train: 301\n",
            "num pos: 364 num neg: 376\n",
            "num pos train: 292 num neg train: 300\n",
            "num pos train: 291 num neg train: 301\n",
            "num pos train: 291 num neg train: 301\n",
            "num pos train: 291 num neg train: 301\n",
            "num pos train: 291 num neg train: 301\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "gaps = 8\n",
        "classification_time=[]\n",
        "cross_fold_ing = 0\n",
        "pc_list=[10,20,30,40,50,60,70,80,90,100,110,150,175,200,225,250,300,350,400,450,500,550,600]\n",
        "\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
        "# import warnings filter\n",
        "from warnings import simplefilter\n",
        "# ignore all future warnings\n",
        "simplefilter(action='ignore', category=FutureWarning)\n",
        "for i  in pc_list:\n",
        "  stats = []\n",
        "  cross_fold_ing=-1\n",
        "  [DataX, LabelY] = Convert_Seq2CKSAAP(prepare_feature_acp740(), gap=8)     \n",
        "  for train_index, test_index in kf.split(DataX,np.argmax(LabelY,axis=1)):\n",
        "      cross_fold_ing = cross_fold_ing + 1\n",
        "      X_train, X_test = DataX[train_index], DataX[test_index]\n",
        "      y_train, y_test = LabelY[train_index], LabelY[test_index]\n",
        "      print('num pos train:', sum(y_train[:,0]==1), 'num neg train:', sum(y_train[:,0]==0))\n",
        "      y_train = y_train[:,0]\n",
        "      y_test=y_test[:,0]  \n",
        "\n",
        "      print('Fold # ', cross_fold_ing)\n",
        "      ## pre-processing PCA\n",
        "      normalizer = Normalizer().fit(X_train)  \n",
        "      X_train = normalizer.transform(X_train)\n",
        "      X_test = normalizer.transform(X_test)\n",
        "      oversampler = KMeansSMOTE(random_state=42)    \n",
        "      X_train, y_train = oversampler.fit_resample(X_train, y_train)\n",
        "      print('After Resampling \\n','num pos train:', sum(y_train==1), 'num neg train:', sum(y_train==0))\n",
        "      transformer = KernelPCA(n_components=i, kernel='poly') # 'linear', 'poly', 'rbf', ‘sigmoid’, ‘cosine’\n",
        "      transformer.fit_transform(X_train)\n",
        "      X_train = transformer.transform(X_train)\n",
        "      X_test = transformer.transform(X_test)  \n",
        "      X_train = np.transpose(X_train)\n",
        "      X_test = np.transpose(X_test)\n",
        "      y_test_pred,y_test_score,time= Test_SRC(X_train,y_train,X_test,y_test,solver='BP',verbose=0, x0=None, ATinvAAT=None, nnz=None, positive=True, tol=1E-4, niter=100, biter=32)\n",
        "\n",
        "      # tr_acc, tr_sen, tr_spe, tr_f1, tr_mcc, tr_bacc, tr_yi = Calculate_Stats(y_train, y_train_pred)\n",
        "      t_acc, t_sen, t_spe, t_f1, t_mcc, t_bacc, t_yi = Calculate_Stats(y_test,y_test_pred)\n",
        "      \n",
        "      print(t_acc, t_sen, t_spe, t_f1, t_mcc, t_bacc, t_yi,time)\n",
        "\n",
        "      stats.append([t_acc, t_sen, t_spe, t_f1, t_mcc, t_bacc, t_yi])\n",
        "      classification_time.append(time)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  print('Mean stats:', np.mean(stats,axis=0))\n",
        "  print('Mean stats:', np.mean(classification_time,axis=0))\n",
        "  print('Std stats:', np.std(stats,axis=0))\n",
        "  x=np.mean(stats,axis=0)\n",
        "  print(\"B_ACC={}, MCC={}, Youden's_index={}\".format(x[5],x[4],x[6]))\n",
        "  ###AUC ROC CURVE\n",
        "  r_auc = roc_auc_score(y_test,y_test_score)\n",
        "  r_fpr, r_tpr, _ = roc_curve(y_test,y_test_score)\n",
        "  plt.plot(r_fpr, r_tpr, linestyle='--', label='ACP_SRC (AUROC = %0.3f)' % r_auc)\n",
        "\n",
        "  # Title\n",
        "  plt.title('ROC Plot')\n",
        "  # Axis labels\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  # Show legend\n",
        "  plt.legend() # \n",
        "  # Show plot\n",
        "  plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}