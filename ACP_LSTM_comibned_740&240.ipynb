{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ehtisham-Fazal/ACP_SRC/blob/main/ACP_LSTM_comibned_740%26240.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3qjT4CaIHnj"
      },
      "source": [
        "**ACP-DA: Improving the Prediction of Anticancer Peptides Using Data Augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "eWHmjNt4DNin",
        "outputId": "7372223b-4e7c-473e-b884-34c58ed9958e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=418cc51696143a771283e231ff27a63e6c086f93de13c856d20cf22663adbfcc\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'acp740.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout, Activation, GRU, SimpleRNN\n",
        "from keras.callbacks import ModelCheckpoint,TensorBoard\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "import scipy.io as sio\n",
        "import numpy as np\n",
        "from numpy import linalg as la\n",
        "import argparse\n",
        "!pip install wget\n",
        "import wget\n",
        "\n",
        "dataset_path='https://raw.githubusercontent.com/haichengyi/ACP-DL/master/acp240.txt'\n",
        "wget.download(dataset_path, 'acp240.txt')\n",
        "dataset_path='https://raw.githubusercontent.com/haichengyi/ACP-DL/master/acp740.txt'\n",
        "wget.download(dataset_path, 'acp740.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lTt-d4isCZ5w"
      },
      "outputs": [],
      "source": [
        "def TransDict_from_list(groups):\n",
        "    transDict = dict()\n",
        "    tar_list = ['0', '1', '2', '3', '4', '5', '6']\n",
        "    result = {}\n",
        "    index = 0\n",
        "    for group in groups:\n",
        "        g_members = sorted(group)  # Alphabetically sorted list\n",
        "        for c in g_members:            \n",
        "            result[c] = str(tar_list[index])  # K:V map, use group's first letter as represent.\n",
        "        index = index + 1\n",
        "    return result\n",
        "\n",
        "def get_3_protein_trids():\n",
        "    nucle_com = []\n",
        "    chars = ['0', '1', '2', '3', '4', '5', '6']\n",
        "    base = len(chars)\n",
        "    end = len(chars) ** 3\n",
        "    for i in range(0, end):\n",
        "        n = i\n",
        "        ch0 = chars[n % base]\n",
        "        n = n / base\n",
        "        ch1 = chars[int(n % base)]\n",
        "        n = n / base\n",
        "        ch2 = chars[int(n % base)]\n",
        "        nucle_com.append(ch0 + ch1 + ch2)\n",
        "    return nucle_com\n",
        "\n",
        "def translate_sequence(seq, TranslationDict):\n",
        "    '''\n",
        "    Given (seq) - a string/sequence to translate,\n",
        "    Translates into a reduced alphabet, using a translation dict provided\n",
        "    by the TransDict_from_list() method.\n",
        "    Returns the string/sequence in the new, reduced alphabet.\n",
        "    Remember - in Python string are immutable..\n",
        "    '''\n",
        "    import string\n",
        "    from_list = []\n",
        "    to_list = []\n",
        "    for k, v in TranslationDict.items():\n",
        "        from_list.append(k)\n",
        "        to_list.append(v)    \n",
        "    TRANS_seq = seq.translate(str.maketrans(str(from_list), str(to_list)))    \n",
        "    return TRANS_seq\n",
        "\n",
        "def get_4_nucleotide_composition(tris, seq, pythoncount=True):\n",
        "    seq_len = len(seq)\n",
        "    tri_feature = [0] * len(tris)\n",
        "    k = len(tris[0])\n",
        "    note_feature = [[0 for cols in range(len(seq) - k + 1)] for rows in range(len(tris))]\n",
        "    if pythoncount:\n",
        "        for val in tris:\n",
        "            num = seq.count(val)\n",
        "            tri_feature.append(float(num) / seq_len)\n",
        "    else:        \n",
        "        for x in range(len(seq) + 1 - k):\n",
        "            kmer = seq[x:x + k]\n",
        "            if kmer in tris:\n",
        "                ind = tris.index(kmer)                \n",
        "                note_feature[ind][x] = note_feature[ind][x] + 1       \n",
        "        u, s, v = la.svd(note_feature)\n",
        "        for i in range(len(s)):\n",
        "            tri_feature = tri_feature + u[i] * s[i] / seq_len\n",
        "    return tri_feature\n",
        "\n",
        "def prepare_feature_acp740():\n",
        "    label = []\n",
        "    interaction_pair = {}\n",
        "    RNA_seq_dict = {}\n",
        "    protein_seq_dict = {}\n",
        "    protein_index = 0\n",
        "    with open('acp740.txt', 'r') as fp:\n",
        "        for line in fp:\n",
        "            if line[0] == '>':\n",
        "                values = line[1:].strip().split('|')\n",
        "                label_temp = values[1]\n",
        "                proteinName = values[0]\n",
        "                if label_temp == '1':\n",
        "                    label.append(1)\n",
        "                else:\n",
        "                    label.append(0)\n",
        "            else:\n",
        "                seq = line[:-1]\n",
        "                protein_seq_dict[protein_index] = seq\n",
        "                protein_index = protein_index + 1   \n",
        "    groups = ['AGV', 'ILFP', 'YMTS', 'HNQW', 'RK', 'DE', 'C']\n",
        "    group_dict = TransDict_from_list(groups)\n",
        "    protein_tris = get_3_protein_trids()    \n",
        "    bpf=[]\n",
        "    kmer=[]\n",
        "    for i in protein_seq_dict: \n",
        "        protein_seq = translate_sequence(protein_seq_dict[i], group_dict)\n",
        "        bpf_feature = BPF(protein_seq_dict[i])       \n",
        "        protein_tri_fea = get_4_nucleotide_composition(protein_tris, protein_seq, pythoncount =False)\n",
        "\n",
        "        bpf.append(bpf_feature)\n",
        "        kmer.append(protein_tri_fea)\n",
        "    return np.array(bpf), np.array(kmer), label\n",
        "\n",
        "def prepare_feature_acp240():\n",
        "    label = []\n",
        "    interaction_pair = {}\n",
        "    RNA_seq_dict = {}\n",
        "    protein_seq_dict = {}\n",
        "    protein_index = 1\n",
        "    with open('acp240.txt', 'r') as fp:\n",
        "        for line in fp:\n",
        "            if line[0] == '>':\n",
        "                values = line[1:].strip().split('|')\n",
        "                label_temp = values[1]\n",
        "                protein = values[0]\n",
        "                if label_temp=='1':\n",
        "                    label.append(1)\n",
        "                else:\n",
        "                    label.append(0)\n",
        "            else:\n",
        "                seq = line[:-1]\n",
        "                protein_seq_dict[protein_index] = seq\n",
        "                protein_index = protein_index + 1    \n",
        "    groups = ['AGV', 'ILFP', 'YMTS', 'HNQW', 'RK', 'DE', 'C']\n",
        "    group_dict = TransDict_from_list(groups)\n",
        "    protein_tris = get_3_protein_trids()    \n",
        "    bpf = []\n",
        "    kmer = []    \n",
        "    for i in protein_seq_dict:  \n",
        "\n",
        "        protein_seq = translate_sequence(protein_seq_dict[i], group_dict)\n",
        "        bpf_feature = BPF(protein_seq_dict[i])        \n",
        "        protein_tri_fea = get_4_nucleotide_composition(protein_tris, protein_seq, pythoncount =False)\n",
        "\n",
        "        bpf.append(bpf_feature)\n",
        "        kmer.append(protein_tri_fea)\n",
        "        protein_index = protein_index + 1     \n",
        "\n",
        "    return np.array(bpf), np.array(kmer), label\n",
        "\n",
        "def BPF(seq_temp):\n",
        "    seq = seq_temp\n",
        "    chars = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
        "    fea = []\n",
        "    tem_vec =[]\n",
        "    k = 7\n",
        "    for i in range(k):\n",
        "        if seq[i] =='A':\n",
        "            tem_vec = [1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "        elif seq[i]=='C':\n",
        "            tem_vec = [0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "        elif seq[i]=='D':\n",
        "            tem_vec = [0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "        elif seq[i]=='E':\n",
        "            tem_vec = [0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "        elif seq[i]=='F':\n",
        "            tem_vec = [0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "        elif seq[i]=='G':\n",
        "            tem_vec = [0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "        elif seq[i]=='H':\n",
        "            tem_vec = [0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "        elif seq[i]=='I':\n",
        "            tem_vec = [0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "        elif seq[i]=='K':\n",
        "            tem_vec = [0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0]\n",
        "        elif seq[i]=='L':\n",
        "            tem_vec = [0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0]\n",
        "        elif seq[i]=='M':\n",
        "            tem_vec = [0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0]\n",
        "        elif seq[i]=='N':\n",
        "            tem_vec = [0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0]\n",
        "        elif seq[i]=='P':\n",
        "            tem_vec = [0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0]\n",
        "        elif seq[i]=='Q':\n",
        "            tem_vec = [0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0]\n",
        "        elif seq[i]=='R':\n",
        "            tem_vec = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0]\n",
        "        elif seq[i]=='S':\n",
        "            tem_vec = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0]\n",
        "        elif seq[i]=='T':\n",
        "            tem_vec = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0]\n",
        "        elif seq[i]=='V':\n",
        "            tem_vec = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0]\n",
        "        elif seq[i]=='W':\n",
        "            tem_vec = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0]\n",
        "        elif seq[i]=='Y':\n",
        "            tem_vec = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1]\n",
        "        fea = fea + tem_vec\n",
        "    return fea\n",
        "\n",
        "def prepare_feature():\n",
        "    label = []\n",
        "    interaction_pair = {}\n",
        "    RNA_seq_dict = {}\n",
        "    protein_seq_dict = {}\n",
        "    protein_index = 1\n",
        "    with open('acp740.txt', 'r') as fp:\n",
        "        for line in fp:\n",
        "            if line[0] == '>':\n",
        "                values = line[1:].strip().split('|')\n",
        "                label_temp = values[1]\n",
        "                protein = values[0]\n",
        "                if label_temp == '1':\n",
        "                    label.append(1)\n",
        "                else:\n",
        "                    label.append(0)\n",
        "            else:\n",
        "                seq = line[:-1]\n",
        "                protein_seq_dict[protein_index] = seq\n",
        "                protein_index = protein_index + 1    \n",
        "    groups = ['AGV', 'ILFP', 'YMTS', 'HNQW', 'RK', 'DE', 'C']\n",
        "    group_dict = TransDict_from_list(groups)\n",
        "    protein_tris = get_3_protein_trids()   \n",
        "    train = []\n",
        "    # get protein feature   \n",
        "    for i in protein_seq_dict: \n",
        "        protein_seq = translate_sequence(protein_seq_dict[i], group_dict)       \n",
        "        protein_tri_fea = get_4_nucleotide_composition(protein_tris, protein_seq, pythoncount =False)\n",
        "\n",
        "        train.append(protein_tri_fea)\n",
        "        protein_index = protein_index + 1       \n",
        "    return np.array(train), label\n",
        "def calculate_performace(test_num, pred_y, labels):\n",
        "    tp = 0\n",
        "    fp = 0\n",
        "    tn = 0\n",
        "    fn = 0\n",
        "    for index in range(test_num):\n",
        "        if labels[index] == 1:\n",
        "            if labels[index] == pred_y[index]:\n",
        "                tp = tp + 1\n",
        "            else:\n",
        "                fn = fn + 1\n",
        "        else:\n",
        "            if labels[index] == pred_y[index]:\n",
        "                tn = tn + 1\n",
        "            else:\n",
        "                fp = fp + 1\n",
        "\n",
        "    acc = float(tp + tn) / test_num\n",
        "    precision = float(tp) / (tp + fp)\n",
        "    sensitivity = float(tp) / (tp + fn)\n",
        "    specificity = float(tn) / (tn + fp)\n",
        "    MCC = float(tp * tn - fp * fn) / (np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)))\n",
        "    return acc, precision, sensitivity, specificity, MCC\n",
        "\n",
        "def transfer_label_from_prob(proba):\n",
        "    label = [1 if val >= 0.5 else 0 for val in proba]\n",
        "    return label\n",
        "def plot_roc_curve(labels, probality, legend_text, auc_tag=True):    \n",
        "    fpr, tpr, thresholds = roc_curve(labels, probality)  \n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    if auc_tag:\n",
        "        rects1 = plt.plot(fpr, tpr, label=legend_text + ' (AUC=%6.3f) ' % roc_auc)\n",
        "    else:\n",
        "        rects1 = plt.plot(fpr, tpr, label=legend_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-dLqCb6BE4oP",
        "outputId": "500b7b28-e70d-42a9-b087-119cbd91b997"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm1 (LSTM)                (None, 128)               313344    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " full_connect (Dense)        (None, 1)                 129       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 313,473\n",
            "Trainable params: 313,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Compiling the Model...\n",
            "Train...\n",
            "Epoch 1/30\n",
            "25/25 [==============================] - 4s 7ms/step - loss: 0.6777 - accuracy: 0.6288\n",
            "Epoch 2/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.6321 - accuracy: 0.7564\n",
            "Epoch 3/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.5787 - accuracy: 0.7832\n",
            "Epoch 4/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.5181 - accuracy: 0.7972\n",
            "Epoch 5/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.4595 - accuracy: 0.8176\n",
            "Epoch 6/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.4144 - accuracy: 0.8240\n",
            "Epoch 7/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3822 - accuracy: 0.8355\n",
            "Epoch 8/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3557 - accuracy: 0.8457\n",
            "Epoch 9/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3364 - accuracy: 0.8622\n",
            "Epoch 10/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3234 - accuracy: 0.8648\n",
            "Epoch 11/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3090 - accuracy: 0.8673\n",
            "Epoch 12/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2959 - accuracy: 0.8673\n",
            "Epoch 13/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2864 - accuracy: 0.8776\n",
            "Epoch 14/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2784 - accuracy: 0.8890\n",
            "Epoch 15/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2684 - accuracy: 0.8916\n",
            "Epoch 16/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2602 - accuracy: 0.8865\n",
            "Epoch 17/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2523 - accuracy: 0.8954\n",
            "Epoch 18/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2445 - accuracy: 0.8954\n",
            "Epoch 19/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2375 - accuracy: 0.8941\n",
            "Epoch 20/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2302 - accuracy: 0.9005\n",
            "Epoch 21/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2254 - accuracy: 0.9107\n",
            "Epoch 22/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2165 - accuracy: 0.9145\n",
            "Epoch 23/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2088 - accuracy: 0.9145\n",
            "Epoch 24/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2001 - accuracy: 0.9184\n",
            "Epoch 25/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1970 - accuracy: 0.9158\n",
            "Epoch 26/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.1880 - accuracy: 0.9145\n",
            "Epoch 27/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.1804 - accuracy: 0.9286\n",
            "Epoch 28/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1751 - accuracy: 0.9337\n",
            "Epoch 29/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.1725 - accuracy: 0.9349\n",
            "Epoch 30/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.1610 - accuracy: 0.9426\n",
            "(784, 1, 483)\n",
            "(196, 1, 483)\n",
            "0.7397959183673469 0.7475728155339806 0.7549019607843137 0.723404255319149 0.4785308609140181\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm1 (LSTM)                (None, 128)               313344    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " full_connect (Dense)        (None, 1)                 129       \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 313,473\n",
            "Trainable params: 313,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Compiling the Model...\n",
            "Train...\n",
            "Epoch 1/30\n",
            "25/25 [==============================] - 2s 7ms/step - loss: 0.6800 - accuracy: 0.6173\n",
            "Epoch 2/30\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.6396 - accuracy: 0.7717\n",
            "Epoch 3/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.5907 - accuracy: 0.7908\n",
            "Epoch 4/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.5332 - accuracy: 0.8048\n",
            "Epoch 5/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.4764 - accuracy: 0.8240\n",
            "Epoch 6/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.4316 - accuracy: 0.8355\n",
            "Epoch 7/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3944 - accuracy: 0.8482\n",
            "Epoch 8/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3695 - accuracy: 0.8559\n",
            "Epoch 9/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3494 - accuracy: 0.8610\n",
            "Epoch 10/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3330 - accuracy: 0.8584\n",
            "Epoch 11/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3165 - accuracy: 0.8712\n",
            "Epoch 12/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3079 - accuracy: 0.8763\n",
            "Epoch 13/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2959 - accuracy: 0.8890\n",
            "Epoch 14/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2888 - accuracy: 0.8865\n",
            "Epoch 15/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2814 - accuracy: 0.8903\n",
            "Epoch 16/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2744 - accuracy: 0.8929\n",
            "Epoch 17/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2669 - accuracy: 0.8980\n",
            "Epoch 18/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2582 - accuracy: 0.9056\n",
            "Epoch 19/30\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2514 - accuracy: 0.9069\n",
            "Epoch 20/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2443 - accuracy: 0.9107\n",
            "Epoch 21/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2392 - accuracy: 0.9056\n",
            "Epoch 22/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2281 - accuracy: 0.9133\n",
            "Epoch 23/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2217 - accuracy: 0.9107\n",
            "Epoch 24/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2186 - accuracy: 0.9196\n",
            "Epoch 25/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2090 - accuracy: 0.9196\n",
            "Epoch 26/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2028 - accuracy: 0.9235\n",
            "Epoch 27/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2000 - accuracy: 0.9209\n",
            "Epoch 28/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.1911 - accuracy: 0.9260\n",
            "Epoch 29/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1842 - accuracy: 0.9362\n",
            "Epoch 30/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.1781 - accuracy: 0.9311\n",
            "(784, 1, 483)\n",
            "(196, 1, 483)\n",
            "0.8112244897959183 0.8076923076923077 0.8316831683168316 0.7894736842105263 0.6220326583367841\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm1 (LSTM)                (None, 128)               313344    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " full_connect (Dense)        (None, 1)                 129       \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 313,473\n",
            "Trainable params: 313,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Compiling the Model...\n",
            "Train...\n",
            "Epoch 1/30\n",
            "25/25 [==============================] - 2s 7ms/step - loss: 0.6811 - accuracy: 0.6084\n",
            "Epoch 2/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.6352 - accuracy: 0.7551\n",
            "Epoch 3/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.5820 - accuracy: 0.7755\n",
            "Epoch 4/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.5226 - accuracy: 0.7934\n",
            "Epoch 5/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.8036\n",
            "Epoch 6/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.4261 - accuracy: 0.8125\n",
            "Epoch 7/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3941 - accuracy: 0.8342\n",
            "Epoch 8/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3697 - accuracy: 0.8431\n",
            "Epoch 9/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3518 - accuracy: 0.8495\n",
            "Epoch 10/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3408 - accuracy: 0.8520\n",
            "Epoch 11/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3253 - accuracy: 0.8622\n",
            "Epoch 12/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3117 - accuracy: 0.8686\n",
            "Epoch 13/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3014 - accuracy: 0.8699\n",
            "Epoch 14/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2957 - accuracy: 0.8724\n",
            "Epoch 15/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2859 - accuracy: 0.8737\n",
            "Epoch 16/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2763 - accuracy: 0.8827\n",
            "Epoch 17/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2674 - accuracy: 0.8763\n",
            "Epoch 18/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2628 - accuracy: 0.8852\n",
            "Epoch 19/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2532 - accuracy: 0.8967\n",
            "Epoch 20/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2461 - accuracy: 0.8980\n",
            "Epoch 21/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2376 - accuracy: 0.9069\n",
            "Epoch 22/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2309 - accuracy: 0.9043\n",
            "Epoch 23/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2291 - accuracy: 0.9069\n",
            "Epoch 24/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2188 - accuracy: 0.9094\n",
            "Epoch 25/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2071 - accuracy: 0.9209\n",
            "Epoch 26/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.1993 - accuracy: 0.9235\n",
            "Epoch 27/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1953 - accuracy: 0.9298\n",
            "Epoch 28/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.1937 - accuracy: 0.9247\n",
            "Epoch 29/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1837 - accuracy: 0.9337\n",
            "Epoch 30/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.1748 - accuracy: 0.9401\n",
            "(784, 1, 483)\n",
            "(196, 1, 483)\n",
            "0.8112244897959183 0.8333333333333334 0.7920792079207921 0.8315789473684211 0.6234957231585015\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm1 (LSTM)                (None, 128)               313344    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " full_connect (Dense)        (None, 1)                 129       \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 313,473\n",
            "Trainable params: 313,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Compiling the Model...\n",
            "Train...\n",
            "Epoch 1/30\n",
            "25/25 [==============================] - 2s 7ms/step - loss: 0.6795 - accuracy: 0.6365\n",
            "Epoch 2/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.6358 - accuracy: 0.7806\n",
            "Epoch 3/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.5854 - accuracy: 0.7857\n",
            "Epoch 4/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.5281 - accuracy: 0.7997\n",
            "Epoch 5/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.4738 - accuracy: 0.8099\n",
            "Epoch 6/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.4334 - accuracy: 0.8265\n",
            "Epoch 7/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3971 - accuracy: 0.8367\n",
            "Epoch 8/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3734 - accuracy: 0.8406\n",
            "Epoch 9/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3549 - accuracy: 0.8444\n",
            "Epoch 10/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3377 - accuracy: 0.8495\n",
            "Epoch 11/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3267 - accuracy: 0.8546\n",
            "Epoch 12/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3151 - accuracy: 0.8584\n",
            "Epoch 13/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3028 - accuracy: 0.8750\n",
            "Epoch 14/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2943 - accuracy: 0.8699\n",
            "Epoch 15/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2862 - accuracy: 0.8788\n",
            "Epoch 16/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2788 - accuracy: 0.8750\n",
            "Epoch 17/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2675 - accuracy: 0.8865\n",
            "Epoch 18/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2589 - accuracy: 0.8852\n",
            "Epoch 19/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2504 - accuracy: 0.8980\n",
            "Epoch 20/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2449 - accuracy: 0.9031\n",
            "Epoch 21/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2351 - accuracy: 0.9043\n",
            "Epoch 22/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2311 - accuracy: 0.9031\n",
            "Epoch 23/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2247 - accuracy: 0.9107\n",
            "Epoch 24/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2169 - accuracy: 0.9133\n",
            "Epoch 25/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2066 - accuracy: 0.9222\n",
            "Epoch 26/30\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.2011 - accuracy: 0.9196\n",
            "Epoch 27/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.1901 - accuracy: 0.9362\n",
            "Epoch 28/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1855 - accuracy: 0.9337\n",
            "Epoch 29/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.1797 - accuracy: 0.9388\n",
            "Epoch 30/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1691 - accuracy: 0.9490\n",
            "(784, 1, 483)\n",
            "(196, 1, 483)\n",
            "0.7806122448979592 0.7543859649122807 0.8514851485148515 0.7052631578947368 0.5640557649311613\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm1 (LSTM)                (None, 128)               313344    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " full_connect (Dense)        (None, 1)                 129       \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 313,473\n",
            "Trainable params: 313,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Compiling the Model...\n",
            "Train...\n",
            "Epoch 1/30\n",
            "25/25 [==============================] - 2s 7ms/step - loss: 0.6748 - accuracy: 0.6441\n",
            "Epoch 2/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.6246 - accuracy: 0.7755\n",
            "Epoch 3/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.5660 - accuracy: 0.8010\n",
            "Epoch 4/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.5051 - accuracy: 0.8189\n",
            "Epoch 5/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.4523 - accuracy: 0.8291\n",
            "Epoch 6/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.8367\n",
            "Epoch 7/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3834 - accuracy: 0.8393\n",
            "Epoch 8/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3624 - accuracy: 0.8495\n",
            "Epoch 9/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3441 - accuracy: 0.8495\n",
            "Epoch 10/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3299 - accuracy: 0.8559\n",
            "Epoch 11/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3192 - accuracy: 0.8648\n",
            "Epoch 12/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3083 - accuracy: 0.8661\n",
            "Epoch 13/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2994 - accuracy: 0.8699\n",
            "Epoch 14/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2894 - accuracy: 0.8686\n",
            "Epoch 15/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2820 - accuracy: 0.8776\n",
            "Epoch 16/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2744 - accuracy: 0.8801\n",
            "Epoch 17/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2650 - accuracy: 0.8865\n",
            "Epoch 18/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2561 - accuracy: 0.8903\n",
            "Epoch 19/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2488 - accuracy: 0.8941\n",
            "Epoch 20/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2434 - accuracy: 0.9031\n",
            "Epoch 21/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2341 - accuracy: 0.9082\n",
            "Epoch 22/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2266 - accuracy: 0.9082\n",
            "Epoch 23/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2227 - accuracy: 0.9043\n",
            "Epoch 24/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2109 - accuracy: 0.9133\n",
            "Epoch 25/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2066 - accuracy: 0.9158\n",
            "Epoch 26/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1993 - accuracy: 0.9196\n",
            "Epoch 27/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1924 - accuracy: 0.9222\n",
            "Epoch 28/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.1843 - accuracy: 0.9286\n",
            "Epoch 29/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.1804 - accuracy: 0.9298\n",
            "Epoch 30/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.1708 - accuracy: 0.9375\n",
            "(784, 1, 483)\n",
            "(196, 1, 483)\n",
            "0.7857142857142857 0.8085106382978723 0.76 0.8125 0.5728581482990276\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "mean performance of ACP_DL\n",
            "[0.78571429 0.79029901 0.7980299  0.77244401 0.57219463]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# define parameters\n",
        "data_dim = 483\n",
        "timesteps = 1\n",
        "batch_size = 32   \n",
        "epochs = 30\n",
        "# get data\n",
        "bpf_1, kmer_1, label_1 = prepare_feature_acp740()\n",
        "bpf, kmer, label_2 = prepare_feature_acp240()\n",
        "X = np.concatenate((bpf, kmer), axis=1)\n",
        "y= np.concatenate((bpf_1, kmer_1), axis=1)\n",
        "Datax=np.concatenate((X,y))\n",
        "label=label_2+label_1\n",
        "label=np.array(label)\n",
        "X = np.reshape(Datax, (len(Datax), timesteps, data_dim))\n",
        "# split data\n",
        "num_cross_val = 5  # 5-fold\n",
        "all_performance_lstm = []\n",
        "all_labels = []\n",
        "all_prob = {}\n",
        "num_classifier = 3\n",
        "all_prob[0] = []\n",
        "all_average = []\n",
        "\n",
        "for fold in range(num_cross_val):\n",
        "    train = np.array([x for i, x in enumerate(X) if i % num_cross_val != fold])\n",
        "    test = np.array([x for i, x in enumerate(X) if i % num_cross_val == fold])\n",
        "    train_label = np.array([x for i, x in enumerate(label) if i % num_cross_val != fold])\n",
        "    test_label = np.array([x for i, x in enumerate(label) if i % num_cross_val == fold])\n",
        "    real_labels = []\n",
        "    for val in test_label:\n",
        "        if val == 1:\n",
        "            real_labels.append(1)\n",
        "        else:\n",
        "            real_labels.append(0)\n",
        "\n",
        "    train_label_new = []\n",
        "    for val in train_label:\n",
        "        if val == 1:\n",
        "            train_label_new.append(1)\n",
        "        else:\n",
        "            train_label_new.append(0)\n",
        "    all_labels = all_labels + real_labels\n",
        "    \n",
        "    model = Sequential()    \n",
        "    model.add(LSTM(128, return_sequences=False,input_shape=(timesteps, data_dim), name='lstm1'))  # returns a sequence of vectors of dimension 32\n",
        "  \n",
        "    model.add(Dropout(0.25, name='dropout'))\n",
        "    model.add(Dense(1, name='full_connect'))\n",
        "    model.add(Activation('sigmoid'))\n",
        "    model.summary()\n",
        "\n",
        "    print('Compiling the Model...')\n",
        "    model.compile(loss='binary_crossentropy',  #\n",
        "          optimizer='adam',\n",
        "          metrics=['accuracy'])\n",
        "\n",
        "    print(\"Train...\")\n",
        "\n",
        "    model.fit(train, train_label, batch_size=batch_size,epochs=epochs)    \n",
        "    print(train.shape)\n",
        "    print(test.shape)\n",
        "    lstm_proba=model.predict(test)  \n",
        "\n",
        "    all_prob[0] = all_prob[0] + [val for val in lstm_proba]\n",
        "    y_pred_xgb = transfer_label_from_prob(lstm_proba)\n",
        "    acc, precision, sensitivity, specificity, MCC = calculate_performace(len(real_labels), y_pred_xgb, real_labels)\n",
        "    print(acc, precision, sensitivity, specificity, MCC)\n",
        "    all_performance_lstm.append([acc, precision, sensitivity, specificity, MCC])\n",
        "    print('---' * 50)\n",
        "\n",
        "print('mean performance of ACP_DL')\n",
        "print(np.mean(np.array(all_performance_lstm), axis=0))\n",
        "print('---' * 50)\n",
        "\n",
        "plot_roc_curve(all_labels, all_prob[0], 'proposed method')\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([-0.05, 1])\n",
        "plt.ylim([0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x90Dxpo-oTUa",
        "outputId": "bddec1f9-afc7-4263-ea87-cbcc35d90e01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(980, 483)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Datax.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdC0doZ9oTUa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tndYaWnMoTUa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}