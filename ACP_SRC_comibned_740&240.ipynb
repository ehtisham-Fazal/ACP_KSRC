{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ehtisham-Fazal/ACP_SRC/blob/main/ACP_SRC_comibned_740%26240.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ec8db92f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec8db92f",
        "outputId": "767ea34e-a198-46ff-da51-c8cdcb7af075"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=f2d74f6562c62b8535009d9d1ecd0cfb5fe891a747f3ce28a1431e24929a661c\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ],
      "source": [
        "import sys, os, re, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import sample\n",
        "\n",
        "## Models\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, BatchNormalization, Dropout\n",
        "from keras import metrics\n",
        "from keras import optimizers\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "import numpy.linalg as LA\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "## Perfmetrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report, accuracy_score, matthews_corrcoef, balanced_accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.metrics import auc, average_precision_score, precision_recall_curve, roc_curve\n",
        "\n",
        "## utilities\n",
        "from matplotlib import pyplot as plt\n",
        "!pip install wget\n",
        "import wget\n",
        "\n",
        "\n",
        "## pre-processing\n",
        "from sklearn.preprocessing import normalize, Normalizer\n",
        "from sklearn.decomposition import KernelPCA\n",
        "from imblearn.over_sampling import ADASYN, SMOTE, SVMSMOTE, KMeansSMOTE, BorderlineSMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0f32eaa9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0f32eaa9",
        "outputId": "2f7c4837-2629-48a6-f0b2-90de0ab09f69"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'acp740.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "file1_path = 'https://raw.githubusercontent.com/NLPrinceton/sparse_recovery/master/solvers.py'\n",
        "wget.download(file1_path, 'solvers.py')\n",
        "from solvers import *\n",
        "dataset_path='https://raw.githubusercontent.com/haichengyi/ACP-DL/master/acp240.txt'\n",
        "wget.download(dataset_path, 'acp240.txt')\n",
        "dataset_path='https://raw.githubusercontent.com/haichengyi/ACP-DL/master/acp740.txt'\n",
        "wget.download(dataset_path, 'acp740.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "164cc814",
      "metadata": {
        "id": "164cc814"
      },
      "outputs": [],
      "source": [
        "def prepare_feature_acp740():\n",
        "    path = r\"acp740.txt\"\n",
        "    new_list=[]\n",
        "    seq_list=[]\n",
        "    label = []\n",
        "    lis = []\n",
        "    lx=[]\n",
        "    interaction_pair = {}\n",
        "    RNA_seq_dict = {}\n",
        "    protein_seq_dict = {}\n",
        "    protein_index = 0\n",
        "    with open(path, 'r') as fp:\n",
        "        for line in fp:\n",
        "            if line[0] == '>':\n",
        "                values = line[1:].strip().split('|')\n",
        "                label_temp = values[1]            \n",
        "                proteinName = values[0]\n",
        "                proteinName_1=proteinName.split(\"_\")\n",
        "                new_list.append(proteinName_1[0])              \n",
        "                if label_temp == '1':\n",
        "                    label.append(1)\n",
        "                else:\n",
        "                    label.append(0)\n",
        "            else:\n",
        "                seq = line[:-1]\n",
        "                seq_list.append(seq)\n",
        "        for i, item in enumerate(new_list):\n",
        "            lis.append([item, seq_list[i]])\n",
        "        for i in lis:\n",
        "            if len(i[1])>60:\n",
        "                x=([i[0],i[1][0:60]])\n",
        "                lx.append(x)\n",
        "            else:\n",
        "                lx.append(i)        \n",
        "    return lx \n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e644d02a",
      "metadata": {
        "id": "e644d02a"
      },
      "outputs": [],
      "source": [
        "def prepare_feature_acp240():\n",
        "    path = r\"acp240.txt\"\n",
        "    new_list=[]\n",
        "    seq_list=[]\n",
        "    label = []\n",
        "    lis = []\n",
        "    \"\"\" to check the len of sequence below lx is used\"\"\"\n",
        "    lx=[]\n",
        "    interaction_pair = {}\n",
        "    RNA_seq_dict = {}\n",
        "    protein_seq_dict = {}\n",
        "    protein_index = 0\n",
        "    with open(path, 'r') as fp:\n",
        "        for line in fp:\n",
        "            if line[0] == '>':\n",
        "                values = line[1:].strip().split('|')\n",
        "                label_temp = values[1]            \n",
        "                proteinName = values[0]\n",
        "                proteinName_1=proteinName.split(\"_\")\n",
        "                new_list.append(proteinName_1[0])\n",
        "                if label_temp == '1':\n",
        "                    label.append(1)\n",
        "                else:\n",
        "                    label.append(0)\n",
        "            else:\n",
        "                seq = line[:-1]\n",
        "                seq_list.append(seq)\n",
        "        for i, item in enumerate(new_list):\n",
        "            lis.append([item, seq_list[i]])\n",
        "        for i in lis:\n",
        "            if len(i[1])>60:\n",
        "                x=([i[0],i[1][0:60]])\n",
        "                lx.append(x)\n",
        "            else:\n",
        "                lx.append(i)\n",
        "        \n",
        "    return lx "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6b3c418d",
      "metadata": {
        "id": "6b3c418d"
      },
      "outputs": [],
      "source": [
        "def yoden_index(y, y_pred):\n",
        "  epsilon = 1e-30\n",
        "  tn, fp, fn, tp = confusion_matrix(y, y_pred, labels=[0,1]).ravel()\n",
        "  j = (tp/(tp + fn + epsilon)) + (tn/(tn+fp + epsilon)) - 1\n",
        "  return j\n",
        "\n",
        "def pmeasure(y, y_pred):\n",
        "    epsilon = 1e-30\n",
        "    tn, fp, fn, tp = confusion_matrix(y, y_pred, labels=[0,1]).ravel()\n",
        "    sensitivity = tp / (tp + fn + epsilon)\n",
        "    specificity = tn / (tn + fp + epsilon)\n",
        "    f1score = (2 * tp) / (2 * tp + fp + fn + epsilon)\n",
        "    return ({'Sensitivity': sensitivity, 'Specificity': specificity, 'F1-Score': f1score})\n",
        "    \n",
        "def Calculate_Stats(y_actual,y_pred):\n",
        "  acc = accuracy_score(y_actual, y_pred)\n",
        "  sen = pmeasure(y_actual, y_pred)['Sensitivity']\n",
        "  spe = pmeasure(y_actual, y_pred)['Specificity']\n",
        "  f1 = pmeasure(y_actual, y_pred)['F1-Score']\n",
        "  mcc = matthews_corrcoef(y_actual, y_pred)\n",
        "  bacc = balanced_accuracy_score(y_actual, y_pred)\n",
        "  yi = yoden_index(y_actual, y_pred)\n",
        "  return acc, sen, spe, f1, mcc, bacc, yi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c392a070",
      "metadata": {
        "id": "c392a070"
      },
      "outputs": [],
      "source": [
        "def Test_SRC(A,delta_y,DATA,LABEL,solver='BP',verbose=0, x0=None, ATinvAAT=None, nnz=None, positive=False, tol=1E-4, niter=100, biter=32):\n",
        "  LABEL_PRED = []\n",
        "  count = 0\n",
        "  for ind in range(0,DATA.shape[1]):\n",
        "    b = DATA[:,ind]\n",
        "    if(solver=='BP'):     \n",
        "      x = BasisPursuit(A, b, x0=x0, ATinvAAT=ATinvAAT, positive=positive, tol=tol, niter=niter, biter=biter)\n",
        "    elif(solver=='MP'):      \n",
        "      x = MatchingPursuit(A, b, tol=tol, nnz=nnz, positive=positive)\n",
        " \n",
        "    label_out = delta_rule(A,delta_y,x,b)\n",
        "    if (verbose):\n",
        "      check = label_out==LABEL[ind]\n",
        "      if (check):\n",
        "        count = count + 1\n",
        "      accuracy = 100*count/(ind+1)\n",
        "      print(ind+1, count, accuracy, LABEL[ind], label_out, check)\n",
        "    LABEL_PRED.append(label_out)\n",
        "\n",
        "  return np.array(LABEL_PRED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9a0e5eaa",
      "metadata": {
        "id": "9a0e5eaa"
      },
      "outputs": [],
      "source": [
        "def delta_rule(A,delta_y,x,b):\n",
        "  delta1 = 0*x\n",
        "  delta2 = 0*x\n",
        "  delta1[delta_y==1]=x[delta_y==1]\n",
        "  delta2[delta_y==0]=x[delta_y==0]\n",
        "  y1 = np.matmul(A,delta1)\n",
        "  y2 = np.matmul(A,delta2)\n",
        "  r1 = np.linalg.norm(y1-b)\n",
        "  r2 = np.linalg.norm(y2-b)\n",
        "\n",
        "  if(r1<r2):\n",
        "    label = 1\n",
        "  else:\n",
        "    label = 0\n",
        "\n",
        "  return label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "21031082",
      "metadata": {
        "id": "21031082"
      },
      "outputs": [],
      "source": [
        "def Convert_Seq2CKSAAP(train_seq, gap=8):\n",
        "  cksaapfea = []\n",
        "  seq_label = []\n",
        "  for sseq in train_seq:\n",
        "    temp= CKSAAP([sseq], gap=8)\n",
        "    cksaapfea.append(temp[1][1:])\n",
        "    seq_label.append(sseq[0])\n",
        "\n",
        "  x = np.array(cksaapfea)\n",
        "  y = np.array(seq_label)\n",
        "  y[y=='ACP']=1\n",
        "  y[y=='non-ACP']=0\n",
        "  y = to_categorical(y)\n",
        "  print('num pos:', sum(y[:,0]==1), 'num neg:', sum(y[:,0]==0))\n",
        "  return x,y\n",
        "\n",
        "def minSequenceLength(fastas):\n",
        "    minLen = 10000\n",
        "    for i in fastas:\n",
        "        if minLen > len(i[1]):\n",
        "            minLen = len(i[1])\n",
        "    return minLen\n",
        "\n",
        "def CKSAAP(fastas, gap=5, **kw):\n",
        "    if gap < 0:\n",
        "        print('Error: the gap should be equal or greater than zero' + '\\n\\n')\n",
        "        return 0\n",
        "\n",
        "    if minSequenceLength(fastas) < gap+2:\n",
        "        print('Error: all the sequence length should be larger than the (gap value) + 2 = ' + str(gap+2) + '\\n' + 'Current sequence length ='  + str(minSequenceLength(fastas)) + '\\n\\n')\n",
        "        return 0\n",
        "\n",
        "    AA = 'ACDEFGHIKLMNPQRSTVWY'\n",
        "    encodings = []\n",
        "    aaPairs = []\n",
        "    for aa1 in AA:\n",
        "        for aa2 in AA:\n",
        "            aaPairs.append(aa1 + aa2)\n",
        "    header = ['#']\n",
        "    for g in range(gap+1):\n",
        "        for aa in aaPairs:\n",
        "            header.append(aa + '.gap' + str(g))\n",
        "    encodings.append(header)\n",
        "    for i in fastas:\n",
        "        name, sequence = i[0], i[1]\n",
        "        code = [name]\n",
        "        for g in range(gap+1):\n",
        "            myDict = {}\n",
        "            for pair in aaPairs:\n",
        "                myDict[pair] = 0\n",
        "            sum = 0\n",
        "            for index1 in range(len(sequence)):\n",
        "                index2 = index1 + g + 1\n",
        "                if index1 < len(sequence) and index2 < len(sequence) and sequence[index1] in AA and sequence[index2] in AA:\n",
        "                    myDict[sequence[index1] + sequence[index2]] = myDict[sequence[index1] + sequence[index2]] + 1\n",
        "                    sum = sum + 1\n",
        "            for pair in aaPairs:\n",
        "                code.append(myDict[pair] / sum)\n",
        "        encodings.append(code)\n",
        "    return encodings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0d062756",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d062756",
        "outputId": "946d6df1-963e-41a9-8cf7-c5a9ca3cd2f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num pos: 475 num neg: 505\n",
            "num pos train: 380 num neg train: 404\n",
            "Fold #  1\n",
            "After Resampling \n",
            " num pos train: 404 num neg train: 404\n",
            "0.8367346938775511 0.8315789473684211 0.8415841584158416 0.8315789473684211 0.6731631057842626 0.8365815528921313 0.6731631057842626\n",
            "num pos train: 380 num neg train: 404\n",
            "Fold #  2\n",
            "After Resampling \n",
            " num pos train: 404 num neg train: 404\n",
            "0.75 0.7473684210526316 0.7524752475247525 0.743455497382199 0.49971348400203436 0.749921834288692 0.49984366857738394\n",
            "num pos train: 380 num neg train: 404\n",
            "Fold #  3\n",
            "After Resampling \n",
            " num pos train: 404 num neg train: 404\n",
            "0.8571428571428571 0.8 0.9108910891089109 0.8444444444444444 0.716893442298939 0.8554455445544555 0.7108910891089111\n",
            "num pos train: 380 num neg train: 404\n",
            "Fold #  4\n",
            "After Resampling \n",
            " num pos train: 404 num neg train: 404\n",
            "0.7704081632653061 0.7684210526315789 0.7722772277227723 0.7643979057591623 0.5405574551715083 0.7703491401771756 0.5406982803543512\n",
            "num pos train: 380 num neg train: 404\n",
            "Fold #  5\n",
            "After Resampling \n",
            " num pos train: 404 num neg train: 404\n",
            "0.7704081632653061 0.7578947368421053 0.7821782178217822 0.7619047619047619 0.5402700667266899 0.7700364773319437 0.5400729546638874\n",
            "Mean stats: [0.79693878 0.78105263 0.81188119 0.78915631 0.59411951 0.79646691\n",
            " 0.59293382]\n",
            "Std stats: [0.0419982  0.03079734 0.0577322  0.04074469 0.08485574 0.04155674\n",
            " 0.08311348]\n",
            "B_ACC=0.7964669098488797, MCC=0.5941195107966869, Youden's_index=0.5929338196977592\n"
          ]
        }
      ],
      "source": [
        "  ## Perform Monte-Carlos Simulations for [num_Trials]# of independent Trials\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "gaps = 8\n",
        "loop_ind = 0\n",
        "stats = []\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=5)\n",
        "# import warnings filter\n",
        "from warnings import simplefilter\n",
        "# ignore all future warnings\n",
        "ALL_seq=prepare_feature_acp740() + prepare_feature_acp240()\n",
        "simplefilter(action='ignore', category=FutureWarning)\n",
        "[DataX, LabelY] = Convert_Seq2CKSAAP(ALL_seq, gap=8)     \n",
        "for train_index, test_index in kf.split(DataX,np.argmax(LabelY,axis=1)):\n",
        "    loop_ind = loop_ind + 1\n",
        "    X_train, X_test = DataX[train_index], DataX[test_index]\n",
        "    y_train, y_test = LabelY[train_index], LabelY[test_index]\n",
        "    print('num pos train:', sum(y_train[:,0]==1), 'num neg train:', sum(y_train[:,0]==0))\n",
        "    y_train = y_train[:,0]\n",
        "    y_test=y_test[:,0]  \n",
        "\n",
        "    print('Fold # ', loop_ind)\n",
        "    ## pre-processing PCA\n",
        "    normalizer = Normalizer().fit(X_train)  # fit does nothing\n",
        "    X_train = normalizer.transform(X_train)\n",
        "    X_test = normalizer.transform(X_test)\n",
        "    oversampler = BorderlineSMOTE(random_state=42)\n",
        "    X_train, y_train = oversampler.fit_resample(X_train, y_train)\n",
        "    print('After Resampling \\n','num pos train:', sum(y_train==1), 'num neg train:', sum(y_train==0))   \n",
        "    transformer = KernelPCA(n_components=100, kernel='poly') # 'linear', 'poly', 'rbf', ‘sigmoid’, ‘cosine’\n",
        "    transformer.fit_transform(X_train)\n",
        "    X_train = transformer.transform(X_train)\n",
        "    X_test = transformer.transform(X_test)  \n",
        "    X_train = np.transpose(X_train)\n",
        "    X_test = np.transpose(X_test)\n",
        "    y_test_pred = Test_SRC(X_train,y_train,X_test,y_test,solver='BP',verbose=0, x0=None, ATinvAAT=None, nnz=None, positive=True, tol=1E-4, niter=100, biter=32)\n",
        "    t_acc, t_sen, t_spe, t_f1, t_mcc, t_bacc, t_yi = Calculate_Stats(y_test,y_test_pred)    \n",
        "    print(t_acc, t_sen, t_spe, t_f1, t_mcc, t_bacc, t_yi)    \n",
        "    stats.append([t_acc, t_sen, t_spe, t_f1, t_mcc, t_bacc, t_yi])\n",
        "\n",
        "print('Mean stats:', np.mean(stats,axis=0))\n",
        "print('Std stats:', np.std(stats,axis=0))\n",
        "x=np.mean(stats,axis=0)\n",
        "print(\"B_ACC={}, MCC={}, Youden's_index={}\".format(x[5],x[4],x[6]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "637bf2fa",
      "metadata": {
        "id": "637bf2fa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}