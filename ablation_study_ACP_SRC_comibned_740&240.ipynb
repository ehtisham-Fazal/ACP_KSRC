{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ehtisham-Fazal/ACP_KSRC/blob/main/ablation_study_ACP_SRC_comibned_740%26240.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ec8db92f",
      "metadata": {
        "id": "ec8db92f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc4e13c0-8aeb-460a-d6d5-6d014c78f912"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=8d30926cee8c967999bf67667288ebf4f7177fa3a75f53fd6b4f0e7f9aba3ed4\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ],
      "source": [
        "import sys, os, re, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import sample\n",
        "\n",
        "## Models\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, BatchNormalization, Dropout\n",
        "from keras import metrics\n",
        "from keras import optimizers\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "import numpy.linalg as LA\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "## Perfmetrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report, accuracy_score, matthews_corrcoef, balanced_accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.metrics import auc, average_precision_score, precision_recall_curve, roc_curve,roc_auc_score\n",
        "\n",
        "## utilities\n",
        "from matplotlib import pyplot as plt\n",
        "!pip install wget\n",
        "import wget\n",
        "\n",
        "\n",
        "## pre-processing\n",
        "from sklearn.preprocessing import normalize, Normalizer\n",
        "from sklearn.decomposition import KernelPCA\n",
        "from imblearn.over_sampling import ADASYN, SMOTE, SVMSMOTE, KMeansSMOTE, BorderlineSMOTE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zXPmempI9Lj",
        "outputId": "7a08f112-1385-400d-ac0b-e62c94bbb883"
      },
      "id": "2zXPmempI9Lj",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "drive_path = '/content/drive/MyDrive/ACP_SRC_Ehtisham_Share/dataset_acp_combined_KPCA/Matching_Pursuit_results/'\n",
        "os.chdir(drive_path)\n",
        "os.getcwd() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "sbJlBZV6ImsE",
        "outputId": "cb5fdd46-2252-4464-dfff-c424ae0039cb"
      },
      "id": "sbJlBZV6ImsE",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/ACP_SRC_Ehtisham_Share/dataset_acp_combined_KPCA/Matching_Pursuit_results'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0f32eaa9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0f32eaa9",
        "outputId": "ce4b7836-05c8-447a-b915-2a31890e4558"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'acp740.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "file1_path = 'https://raw.githubusercontent.com/NLPrinceton/sparse_recovery/master/solvers.py'\n",
        "wget.download(file1_path, 'solvers.py')\n",
        "from solvers import *\n",
        "dataset_path='https://raw.githubusercontent.com/haichengyi/ACP-DL/master/acp240.txt'\n",
        "wget.download(dataset_path, 'acp240.txt')\n",
        "dataset_path='https://raw.githubusercontent.com/haichengyi/ACP-DL/master/acp740.txt'\n",
        "wget.download(dataset_path, 'acp740.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "164cc814",
      "metadata": {
        "id": "164cc814"
      },
      "outputs": [],
      "source": [
        "def prepare_feature_acp740():\n",
        "    path = r\"acp740.txt\"\n",
        "    new_list=[]\n",
        "    seq_list=[]\n",
        "    label = []\n",
        "    lis = []\n",
        "    lx=[]\n",
        "    interaction_pair = {}\n",
        "    RNA_seq_dict = {}\n",
        "    protein_seq_dict = {}\n",
        "    protein_index = 0\n",
        "    with open(path, 'r') as fp:\n",
        "        for line in fp:\n",
        "            if line[0] == '>':\n",
        "                values = line[1:].strip().split('|')\n",
        "                label_temp = values[1]            \n",
        "                proteinName = values[0]\n",
        "                proteinName_1=proteinName.split(\"_\")\n",
        "                new_list.append(proteinName_1[0])              \n",
        "                if label_temp == '1':\n",
        "                    label.append(1)\n",
        "                else:\n",
        "                    label.append(0)\n",
        "            else:\n",
        "                seq = line[:-1]\n",
        "                seq_list.append(seq)\n",
        "        for i, item in enumerate(new_list):\n",
        "            lis.append([item, seq_list[i]])\n",
        "        for i in lis:\n",
        "            if len(i[1])>60:\n",
        "                x=([i[0],i[1][0:60]])\n",
        "                lx.append(x)\n",
        "            else:\n",
        "                lx.append(i)        \n",
        "    return lx \n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e644d02a",
      "metadata": {
        "id": "e644d02a"
      },
      "outputs": [],
      "source": [
        "def prepare_feature_acp240():\n",
        "    path = r\"acp240.txt\"\n",
        "    new_list=[]\n",
        "    seq_list=[]\n",
        "    label = []\n",
        "    lis = []\n",
        "    \"\"\" to check the len of sequence below lx is used\"\"\"\n",
        "    lx=[]\n",
        "    interaction_pair = {}\n",
        "    RNA_seq_dict = {}\n",
        "    protein_seq_dict = {}\n",
        "    protein_index = 0\n",
        "    with open(path, 'r') as fp:\n",
        "        for line in fp:\n",
        "            if line[0] == '>':\n",
        "                values = line[1:].strip().split('|')\n",
        "                label_temp = values[1]            \n",
        "                proteinName = values[0]\n",
        "                proteinName_1=proteinName.split(\"_\")\n",
        "                new_list.append(proteinName_1[0])\n",
        "                if label_temp == '1':\n",
        "                    label.append(1)\n",
        "                else:\n",
        "                    label.append(0)\n",
        "            else:\n",
        "                seq = line[:-1]\n",
        "                seq_list.append(seq)\n",
        "        for i, item in enumerate(new_list):\n",
        "            lis.append([item, seq_list[i]])\n",
        "        for i in lis:\n",
        "            if len(i[1])>60:\n",
        "                x=([i[0],i[1][0:60]])\n",
        "                lx.append(x)\n",
        "            else:\n",
        "                lx.append(i)\n",
        "        \n",
        "    return lx "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6b3c418d",
      "metadata": {
        "id": "6b3c418d"
      },
      "outputs": [],
      "source": [
        "def yoden_index(y, y_pred):\n",
        "  epsilon = 1e-30\n",
        "  tn, fp, fn, tp = confusion_matrix(y, y_pred, labels=[0,1]).ravel()\n",
        "  j = (tp/(tp + fn + epsilon)) + (tn/(tn+fp + epsilon)) - 1\n",
        "  return j\n",
        "\n",
        "def pmeasure(y, y_pred):\n",
        "    epsilon = 1e-30\n",
        "    tn, fp, fn, tp = confusion_matrix(y, y_pred, labels=[0,1]).ravel()\n",
        "    sensitivity = tp / (tp + fn + epsilon)\n",
        "    specificity = tn / (tn + fp + epsilon)\n",
        "    f1score = (2 * tp) / (2 * tp + fp + fn + epsilon)\n",
        "    return ({'Sensitivity': sensitivity, 'Specificity': specificity, 'F1-Score': f1score})\n",
        "    \n",
        "def Calculate_Stats(y_actual,y_pred):\n",
        "  acc = accuracy_score(y_actual, y_pred)\n",
        "  sen = pmeasure(y_actual, y_pred)['Sensitivity']\n",
        "  spe = pmeasure(y_actual, y_pred)['Specificity']\n",
        "  f1 = pmeasure(y_actual, y_pred)['F1-Score']\n",
        "  mcc = matthews_corrcoef(y_actual, y_pred)\n",
        "  bacc = balanced_accuracy_score(y_actual, y_pred)\n",
        "  yi = yoden_index(y_actual, y_pred)\n",
        "  return acc, sen, spe, f1, mcc, bacc, yi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c392a070",
      "metadata": {
        "id": "c392a070"
      },
      "outputs": [],
      "source": [
        "def Test_SRC(A,delta_y,DATA,LABEL,solver='BP',verbose=0, x0=None, ATinvAAT=None, nnz=None, positive=False, tol=1E-4, niter=100, biter=32):\n",
        "  import time\n",
        "  LABEL_PRED = []\n",
        "  SCORE_PRED=[]\n",
        "  count = 0\n",
        "  time_ellapsed = []\n",
        "  for ind in range(0,DATA.shape[1]):\n",
        "    start_time = time.time()\n",
        "    b = DATA[:,ind]\n",
        "    if(solver=='BP'):     \n",
        "      x = BasisPursuit(A, b, x0=x0, ATinvAAT=ATinvAAT, positive=positive, tol=tol, niter=niter, biter=biter)\n",
        "    elif(solver=='MP'):      \n",
        "      x = MatchingPursuit(A, b, tol=tol, nnz=nnz, positive=positive)\n",
        "    elif (solver==\"OP\"):\n",
        "      x = OrthogonalMP(A, b, tol=tol, nnz=nnz, positive=positive)\n",
        " \n",
        "    label_out, score_out = delta_rule(A,delta_y,x,b)\n",
        "    time_ellapsed.append(time.time()-start_time)\n",
        "    if (verbose):\n",
        "      check = label_out==LABEL[ind]\n",
        "      if (check):\n",
        "        count = count + 1\n",
        "      accuracy = 100*count/(ind+1)\n",
        "      print(ind+1, count, accuracy, LABEL[ind], label_out, check)\n",
        "    LABEL_PRED.append(label_out)\n",
        "    SCORE_PRED.append(score_out)\n",
        "\n",
        "  return np.array(LABEL_PRED), np.array(SCORE_PRED),np.array(time_ellapsed )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9a0e5eaa",
      "metadata": {
        "id": "9a0e5eaa"
      },
      "outputs": [],
      "source": [
        "def delta_rule(A,delta_y,x,b):\n",
        "  delta1 = 0*x\n",
        "  delta2 = 0*x\n",
        "  delta1[delta_y==1]=x[delta_y==1]\n",
        "  delta2[delta_y==0]=x[delta_y==0]\n",
        "  y1 = np.matmul(A,delta1)\n",
        "  y2 = np.matmul(A,delta2)\n",
        "  r1 = np.linalg.norm(y1-b)\n",
        "  r2 = np.linalg.norm(y2-b)\n",
        "\n",
        "  if(r1<r2):\n",
        "    label = 1\n",
        "  else:\n",
        "    label = 0\n",
        "  score=(r2)/(r1+r2)\n",
        "\n",
        "  return label, score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "21031082",
      "metadata": {
        "id": "21031082"
      },
      "outputs": [],
      "source": [
        "def Convert_Seq2CKSAAP(train_seq, gap=8):\n",
        "  cksaapfea = []\n",
        "  seq_label = []\n",
        "  for sseq in train_seq:\n",
        "    temp= CKSAAP([sseq], gap=8)\n",
        "    cksaapfea.append(temp[1][1:])\n",
        "    seq_label.append(sseq[0])\n",
        "\n",
        "  x = np.array(cksaapfea)\n",
        "  y = np.array(seq_label)\n",
        "  y[y=='ACP']=1\n",
        "  y[y=='non-ACP']=0\n",
        "  y = to_categorical(y)\n",
        "  print('num pos:', sum(y[:,0]==1), 'num neg:', sum(y[:,0]==0))\n",
        "  return x,y\n",
        "\n",
        "def minSequenceLength(fastas):\n",
        "    minLen = 10000\n",
        "    for i in fastas:\n",
        "        if minLen > len(i[1]):\n",
        "            minLen = len(i[1])\n",
        "    return minLen\n",
        "\n",
        "def CKSAAP(fastas, gap=5, **kw):\n",
        "    if gap < 0:\n",
        "        print('Error: the gap should be equal or greater than zero' + '\\n\\n')\n",
        "        return 0\n",
        "\n",
        "    if minSequenceLength(fastas) < gap+2:\n",
        "        print('Error: all the sequence length should be larger than the (gap value) + 2 = ' + str(gap+2) + '\\n' + 'Current sequence length ='  + str(minSequenceLength(fastas)) + '\\n\\n')\n",
        "        return 0\n",
        "\n",
        "    AA = 'ACDEFGHIKLMNPQRSTVWY'\n",
        "    encodings = []\n",
        "    aaPairs = []\n",
        "    for aa1 in AA:\n",
        "        for aa2 in AA:\n",
        "            aaPairs.append(aa1 + aa2)\n",
        "    header = ['#']\n",
        "    for g in range(gap+1):\n",
        "        for aa in aaPairs:\n",
        "            header.append(aa + '.gap' + str(g))\n",
        "    encodings.append(header)\n",
        "    for i in fastas:\n",
        "        name, sequence = i[0], i[1]\n",
        "        code = [name]\n",
        "        for g in range(gap+1):\n",
        "            myDict = {}\n",
        "            for pair in aaPairs:\n",
        "                myDict[pair] = 0\n",
        "            sum = 0\n",
        "            for index1 in range(len(sequence)):\n",
        "                index2 = index1 + g + 1\n",
        "                if index1 < len(sequence) and index2 < len(sequence) and sequence[index1] in AA and sequence[index2] in AA:\n",
        "                    myDict[sequence[index1] + sequence[index2]] = myDict[sequence[index1] + sequence[index2]] + 1\n",
        "                    sum = sum + 1\n",
        "            for pair in aaPairs:\n",
        "                code.append(myDict[pair] / sum)\n",
        "        encodings.append(code)\n",
        "    return encodings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.io import savemat\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "gaps = 8\n",
        "cross_fold_ing = 0\n",
        "pc_list=[10,20,30,40,50,60,70,80,90,100,110,150,175,200,225,250,300,350,400,450,500,550,600]\n",
        "pc_list=[30]\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
        "# import warnings filter\n",
        "from warnings import simplefilter\n",
        "# ignore all future warnings\n",
        "simplefilter(action='ignore', category=FutureWarning)\n",
        "ALL_seq=prepare_feature_acp740() + prepare_feature_acp240()\n",
        "for num_pc  in pc_list:\n",
        "  stats = []\n",
        "  classification_time=[]\n",
        "  cross_fold_ing=-1\n",
        "  [DataX, LabelY] = Convert_Seq2CKSAAP(ALL_seq, gap=8)     \n",
        "  for train_index, test_index in kf.split(DataX,np.argmax(LabelY,axis=1)):\n",
        "      cross_fold_ing = cross_fold_ing + 1\n",
        "      X_train, X_test = DataX[train_index], DataX[test_index]\n",
        "      y_train, y_test = LabelY[train_index], LabelY[test_index]\n",
        "      print('num pos train:', sum(y_train[:,0]==1), 'num neg train:', sum(y_train[:,0]==0))\n",
        "      y_train = y_train[:,0]\n",
        "      y_test=y_test[:,0]  \n",
        "\n",
        "      print('Fold # ', cross_fold_ing)\n",
        "      ## pre-processing PCA\n",
        "      normalizer = Normalizer().fit(X_train)  \n",
        "      X_train = normalizer.transform(X_train)\n",
        "      X_test = normalizer.transform(X_test)\n",
        "      oversampler = KMeansSMOTE(random_state=42)    \n",
        "      X_train, y_train = oversampler.fit_resample(X_train, y_train)\n",
        "      print('After Resampling \\n','num pos train:', sum(y_train==1), 'num neg train:', sum(y_train==0))\n",
        "      print('After Resampling \\n','num pos test:', sum(y_test==1), 'num neg test:', sum(y_test==0))\n",
        "      transformer = KernelPCA(n_components=num_pc, kernel='poly') # 'linear', 'poly', 'rbf', ‘sigmoid’, ‘cosine’\n",
        "      transformer.fit_transform(X_train)\n",
        "      X_train = transformer.transform(X_train)\n",
        "      X_test = transformer.transform(X_test)  \n",
        "      X_train = np.transpose(X_train)\n",
        "      X_test = np.transpose(X_test)\n",
        "      y_test_pred,y_test_score,elp_time= Test_SRC(X_train,y_train,X_test,y_test,solver='MP',verbose=0, x0=None, ATinvAAT=None, nnz=None, positive=True, tol=1E-4, niter=100, biter=32)\n",
        "\n",
        "      # tr_acc, tr_sen, tr_spe, tr_f1, tr_mcc, tr_bacc, tr_yi = Calculate_Stats(y_train, y_train_pred)\n",
        "      t_acc, t_sen, t_spe, t_f1, t_mcc, t_bacc, t_yi = Calculate_Stats(y_test,y_test_pred)\n",
        "      \n",
        "      print(t_acc, t_sen, t_spe, t_f1, t_mcc, t_bacc, t_yi, elp_time)\n",
        "\n",
        "      stats.append([t_acc, t_sen, t_spe, t_f1, t_mcc, t_bacc, t_yi])\n",
        "      classification_time.append([elp_time])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # print('Mean stats:', np.mean(stats,axis=0))\n",
        "  # print('Mean stats:', np.mean(classification_time,axis=0))\n",
        "  # print('Std stats:', np.std(stats,axis=0))\n",
        "  x=np.mean(stats,axis=0)\n",
        "  # print(\"B_ACC={}, MCC={}, Youden's_index={}\".format(x[5],x[4],x[6]))\n",
        "  ###AUC ROC CURVE\n",
        "  r_auc = roc_auc_score(y_test,y_test_score)\n",
        "  r_fpr, r_tpr, _ = roc_curve(y_test,y_test_score)\n",
        "  plt.plot(r_fpr, r_tpr, linestyle='--', label='ACP_SRC (AUROC = %0.3f)' % r_auc)\n",
        "  # del model  # deletes the existing model\n",
        "  Class_Statistics = np.asarray(stats)\n",
        "  Time_Statistics= np.asarray(classification_time)\n",
        "  filename = 'ACP_KSRC_STATS_CKSAAP_GAP' + str(gaps)+\" SOLVER_MP\" + '_PC' + str(num_pc) + '.mat'\n",
        "  # savemat(filename,{'Time_Statistics':Time_Statistics})\n",
        "  print('SAVING... '+ filename)\n",
        "\n",
        "  # Title\n",
        "  # plt.title('ROC Plot')\n",
        "  # # Axis labels\n",
        "  # plt.xlabel('False Positive Rate')\n",
        "  # plt.ylabel('True Positive Rate')\n",
        "  # Show legend\n",
        "  plt.legend() # \n",
        "  # Show plot\n",
        "  plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lXznMu3-J6i8",
        "outputId": "51a0d2cb-9bc8-4240-d448-7c7c5c63532c"
      },
      "id": "lXznMu3-J6i8",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num pos: 475 num neg: 505\n",
            "num pos train: 380 num neg train: 404\n",
            "Fold #  0\n",
            "After Resampling \n",
            " num pos train: 406 num neg train: 404\n",
            "After Resampling \n",
            " num pos test: 95 num neg test: 101\n",
            "0.7397959183673469 0.7894736842105263 0.693069306930693 0.746268656716418 0.4839319703068801 0.7412714955706097 0.48254299114121935 [0.0156908  0.01809883 0.01678371 0.0196147  0.01869893 0.01772666\n",
            " 0.02151728 0.02110291 0.0191927  0.0180366  0.0182066  0.01294279\n",
            " 0.01654506 0.01777029 0.03862762 0.02774763 0.0133841  0.01375246\n",
            " 0.01670861 0.01455736 0.01839495 0.01669025 0.01981568 0.02314472\n",
            " 0.02131248 0.01546383 0.0205493  0.01872706 0.01803064 0.01783514\n",
            " 0.01964903 0.01932979 0.02271223 0.02142668 0.01934981 0.01727462\n",
            " 0.01420808 0.01934528 0.01565671 0.01613879 0.027282   0.01458597\n",
            " 0.01659799 0.01935482 0.01893497 0.01453018 0.01817179 0.01333165\n",
            " 0.01905751 0.01805949 0.02007961 0.02290225 0.02044249 0.01787806\n",
            " 0.01715088 0.01798129 0.01507902 0.01744652 0.02146816 0.02295208\n",
            " 0.01576066 0.01574111 0.01742125 0.01758623 0.01944447 0.02224541\n",
            " 0.01501465 0.01990747 0.04322839 0.02109075 0.02073979 0.02229047\n",
            " 0.01890588 0.01846337 0.01962829 0.01915312 0.01950717 0.02101922\n",
            " 0.01855946 0.0198102  0.01775837 0.02047586 0.0193541  0.02080441\n",
            " 0.01950336 0.01949978 0.01838088 0.0179863  0.0187099  0.0236938\n",
            " 0.02270842 0.01925373 0.01993489 0.0330689  0.02233744 0.02157879\n",
            " 0.02148104 0.0168035  0.01983142 0.01976371 0.01915884 0.01672292\n",
            " 0.01767063 0.02592659 0.0176816  0.01905227 0.02030444 0.02001429\n",
            " 0.01941395 0.0284009  0.01907516 0.01904249 0.01968575 0.01576757\n",
            " 0.01396179 0.0169394  0.0208838  0.02224016 0.0160625  0.03683996\n",
            " 0.01905847 0.01669574 0.01782703 0.01442909 0.02095437 0.01879025\n",
            " 0.02007937 0.06563687 0.0464747  0.03081584 0.05138803 0.03147459\n",
            " 0.02934456 0.04183817 0.03566122 0.04232621 0.03736591 0.03360581\n",
            " 0.04003477 0.02719975 0.01858306 0.01779675 0.01352739 0.01797986\n",
            " 0.01787543 0.01536512 0.01803279 0.02739453 0.01445317 0.01541471\n",
            " 0.01535273 0.01643014 0.02016473 0.01848602 0.01533198 0.01625538\n",
            " 0.01176572 0.02031898 0.02232909 0.01298046 0.01766944 0.03959346\n",
            " 0.01980567 0.01456809 0.01518369 0.01920342 0.02193046 0.01989555\n",
            " 0.01733899 0.01626754 0.01530123 0.020504   0.01922846 0.02307487\n",
            " 0.02137995 0.02890944 0.02020526 0.01652455 0.02102613 0.02156806\n",
            " 0.02966928 0.02074623 0.01691461 0.01792979 0.02384233 0.01523781\n",
            " 0.01746702 0.01832557 0.01967692 0.01716042 0.02043271 0.0202198\n",
            " 0.02092838 0.0157156  0.01144266 0.01864672]\n",
            "num pos train: 380 num neg train: 404\n",
            "Fold #  1\n",
            "After Resampling \n",
            " num pos train: 406 num neg train: 404\n",
            "After Resampling \n",
            " num pos test: 95 num neg test: 101\n",
            "0.7653061224489796 0.7789473684210526 0.7524752475247525 0.7628865979381443 0.5312012129090335 0.7657113079729025 0.5314226159458051 [0.01740909 0.01606321 0.01546907 0.03458834 0.02223635 0.01887846\n",
            " 0.01474214 0.0225749  0.01558018 0.01590347 0.01556492 0.01602507\n",
            " 0.01398468 0.0182097  0.01748657 0.02032995 0.02048969 0.02190733\n",
            " 0.02090049 0.02036572 0.01894426 0.01741886 0.01530933 0.01904726\n",
            " 0.02342081 0.01970696 0.01536751 0.01637816 0.03225732 0.02037907\n",
            " 0.01571202 0.02152705 0.01861835 0.01874638 0.01947975 0.01716733\n",
            " 0.01975656 0.02014804 0.0280869  0.01900363 0.01981711 0.04227281\n",
            " 0.01568437 0.02005172 0.01353836 0.01861954 0.017061   0.01618505\n",
            " 0.01734686 0.03388858 0.02594066 0.01610065 0.01744771 0.02004218\n",
            " 0.01578474 0.01868248 0.02097702 0.01827192 0.01745105 0.0156548\n",
            " 0.0142436  0.02864885 0.02031946 0.01720285 0.01602697 0.02001929\n",
            " 0.02119827 0.01908112 0.02089024 0.02062249 0.01399469 0.0159018\n",
            " 0.02016163 0.01559329 0.02070236 0.02510738 0.01940799 0.01763082\n",
            " 0.01973414 0.01908922 0.02222371 0.02168417 0.01868606 0.02349091\n",
            " 0.02527285 0.02046394 0.01946664 0.02238202 0.0212965  0.02003384\n",
            " 0.02077031 0.01862717 0.01942563 0.0419004  0.01676702 0.01856709\n",
            " 0.01968956 0.01804376 0.02327394 0.02167463 0.01721048 0.0170486\n",
            " 0.02074647 0.0183568  0.0193007  0.02084661 0.02658463 0.02075958\n",
            " 0.01985216 0.04992914 0.07160783 0.08353019 0.06669426 0.08328533\n",
            " 0.02715182 0.04539967 0.03127074 0.03547215 0.05587554 0.05334544\n",
            " 0.0617702  0.06274199 0.05962014 0.03999043 0.03757477 0.036479\n",
            " 0.05536819 0.06080604 0.03582597 0.0355258  0.04500175 0.04863167\n",
            " 0.06974673 0.04853034 0.05132246 0.03592205 0.03201556 0.05165267\n",
            " 0.03898835 0.04831004 0.03700399 0.04460073 0.04233527 0.05667496\n",
            " 0.06691527 0.04797339 0.05257583 0.05185747 0.07185555 0.07570362\n",
            " 0.05022979 0.04055429 0.03916168 0.06825995 0.06628609 0.04132676\n",
            " 0.15620208 0.06038427 0.05374622 0.04613137 0.07378626 0.09149528\n",
            " 0.09045219 0.04379225 0.04860067 0.05359077 0.05742192 0.03582883\n",
            " 0.04414701 0.05404282 0.09035659 0.08615184 0.07325554 0.06044006\n",
            " 0.05097151 0.04752994 0.05580807 0.10923386 0.0446763  0.04497266\n",
            " 0.03662372 0.05560255 0.04997754 0.0688343  0.04420018 0.05021143\n",
            " 0.05005789 0.05272985 0.04353499 0.05668354 0.06019115 0.03801084\n",
            " 0.04729676 0.0703299  0.07015491 0.08608913]\n",
            "num pos train: 380 num neg train: 404\n",
            "Fold #  2\n",
            "After Resampling \n",
            " num pos train: 406 num neg train: 404\n",
            "After Resampling \n",
            " num pos test: 95 num neg test: 101\n",
            "0.7704081632653061 0.7789473684210526 0.7623762376237624 0.7668393782383419 0.5410699068377959 0.7706618030224075 0.541323606044815 [0.06861019 0.06883383 0.06087613 0.02954483 0.04978943 0.0490036\n",
            " 0.04282045 0.0436244  0.03045058 0.05262041 0.05162597 0.0372653\n",
            " 0.0920155  0.09649849 0.057652   0.07622814 0.06997895 0.04853582\n",
            " 0.10867667 0.04267716 0.03524399 0.03343654 0.04916048 0.05511403\n",
            " 0.04588795 0.03745914 0.05305409 0.05218482 0.05086946 0.05621266\n",
            " 0.05282927 0.05630922 0.0412178  0.05435228 0.05007291 0.08234024\n",
            " 0.07711244 0.04634237 0.04574943 0.04842234 0.03924918 0.04915524\n",
            " 0.08294225 0.04117632 0.05211353 0.05281115 0.06223202 0.07255745\n",
            " 0.04646969 0.03773785 0.04944372 0.1136806  0.03613782 0.05178356\n",
            " 0.07048249 0.06694627 0.04922366 0.04360056 0.04904366 0.05396914\n",
            " 0.03511643 0.10300303 0.1270833  0.0435648  0.03570509 0.03647399\n",
            " 0.03812885 0.04462266 0.05324483 0.04406834 0.07013726 0.03699517\n",
            " 0.05438519 0.04552531 0.04018664 0.04320335 0.04188871 0.09843969\n",
            " 0.04887414 0.04756618 0.05675888 0.04821539 0.04504466 0.06384969\n",
            " 0.04118657 0.06734872 0.05356836 0.05365252 0.06155705 0.05165195\n",
            " 0.06984925 0.07201338 0.05077934 0.04332161 0.04617739 0.05898762\n",
            " 0.05635023 0.07251811 0.04853964 0.05644655 0.05862069 0.04809237\n",
            " 0.04389954 0.05002761 0.06353831 0.07077837 0.04880095 0.08428621\n",
            " 0.1486063  0.09635758 0.08908629 0.0756588  0.04223037 0.10940027\n",
            " 0.05514622 0.07023382 0.05391264 0.06652021 0.04425716 0.05170107\n",
            " 0.05660176 0.05406356 0.05149674 0.04805899 0.04394174 0.04468632\n",
            " 0.06629348 0.11734676 0.05241919 0.03645253 0.04563665 0.087286\n",
            " 0.07812023 0.08594012 0.04935956 0.08336878 0.03325295 0.04794097\n",
            " 0.05774879 0.04760146 0.05247521 0.05800867 0.04092407 0.07559204\n",
            " 0.07753372 0.0791142  0.07085633 0.04755259 0.03484273 0.03845644\n",
            " 0.03404832 0.03477478 0.06126571 0.07065845 0.08669686 0.07436538\n",
            " 0.09371829 0.08129263 0.03760672 0.05366349 0.14960146 0.15979624\n",
            " 0.09581923 0.05356193 0.06436563 0.04899812 0.06477356 0.06467628\n",
            " 0.11198664 0.09865642 0.06362081 0.06282377 0.04550982 0.04272223\n",
            " 0.0607245  0.04553342 0.05189943 0.04636192 0.05262613 0.05023408\n",
            " 0.05182242 0.04619265 0.04025555 0.03929424 0.05193925 0.05356193\n",
            " 0.04675102 0.04695868 0.06689787 0.06890392 0.04440856 0.07322526\n",
            " 0.06949735 0.05235553 0.02746749 0.05514622]\n",
            "num pos train: 380 num neg train: 404\n",
            "Fold #  3\n",
            "After Resampling \n",
            " num pos train: 408 num neg train: 404\n",
            "After Resampling \n",
            " num pos test: 95 num neg test: 101\n",
            "0.7551020408163265 0.7684210526315789 0.7425742574257426 0.7525773195876289 0.5107824175118634 0.7554976550286607 0.5109953100573215 [0.03201175 0.04158831 0.03395057 0.07203841 0.04193521 0.04621124\n",
            " 0.04244733 0.05936265 0.04207373 0.02956271 0.04333544 0.08798599\n",
            " 0.0726397  0.06108403 0.04203725 0.0675869  0.07228756 0.03279352\n",
            " 0.05519891 0.05158424 0.03198195 0.03875518 0.04654646 0.0538578\n",
            " 0.04214454 0.05327988 0.04418826 0.04355049 0.04797173 0.06888747\n",
            " 0.05950236 0.075526   0.05153608 0.05250096 0.04911208 0.06838584\n",
            " 0.04232264 0.05750179 0.04898667 0.11502862 0.08791614 0.04820824\n",
            " 0.06817579 0.03719306 0.13340831 0.13099861 0.26502538 0.13278389\n",
            " 0.09874606 0.20601201 0.07462406 0.03807616 0.03469276 0.04971933\n",
            " 0.04214239 0.06629443 0.11682534 0.15433431 0.05034375 0.05198145\n",
            " 0.04231954 0.04135299 0.0420785  0.0309422  0.04274249 0.03793716\n",
            " 0.03245735 0.0544219  0.05428243 0.05474758 0.05683255 0.06853867\n",
            " 0.09100628 0.05102396 0.03031564 0.05443788 0.15048385 0.04468393\n",
            " 0.06847858 0.17901731 0.05198574 0.09099913 0.04405236 0.04544878\n",
            " 0.0682919  0.0577929  0.10266185 0.06449199 0.06184697 0.0614686\n",
            " 0.02021718 0.01957154 0.04441833 0.01912045 0.02104306 0.02129745\n",
            " 0.01944709 0.02212954 0.02173209 0.01813626 0.02201915 0.0184083\n",
            " 0.01966834 0.02051258 0.02148032 0.01875782 0.01981831 0.02005172\n",
            " 0.02143526 0.01907063 0.01700091 0.02036977 0.01960254 0.02268147\n",
            " 0.01750541 0.01715517 0.02416277 0.01174283 0.02199459 0.01710415\n",
            " 0.01858139 0.01328802 0.01439023 0.0166049  0.01704979 0.01616478\n",
            " 0.01515746 0.01956606 0.01190686 0.01892304 0.01313782 0.01755619\n",
            " 0.01419568 0.02091312 0.01800919 0.02049565 0.0165298  0.0137012\n",
            " 0.01780415 0.01640844 0.01562619 0.01548147 0.01946735 0.02084637\n",
            " 0.01817203 0.01587415 0.01985168 0.04519844 0.01708078 0.01182342\n",
            " 0.01251507 0.01522565 0.01520824 0.01288915 0.01599169 0.0172174\n",
            " 0.01777697 0.01586509 0.01520824 0.01941895 0.01555967 0.0172174\n",
            " 0.0204854  0.01641941 0.01729131 0.0217154  0.01728463 0.02001977\n",
            " 0.01508403 0.01750398 0.02169251 0.01739502 0.01719546 0.01953936\n",
            " 0.01752639 0.0223341  0.01965833 0.02163553 0.01659203 0.01982355\n",
            " 0.02108049 0.01806498 0.01816201 0.01689315 0.02208018 0.01904655\n",
            " 0.01958346 0.02050972 0.02188468 0.01825356 0.02000308 0.01898623\n",
            " 0.01628709 0.02186275 0.0208168  0.01707482]\n",
            "num pos train: 380 num neg train: 404\n",
            "Fold #  4\n",
            "After Resampling \n",
            " num pos train: 405 num neg train: 404\n",
            "After Resampling \n",
            " num pos test: 95 num neg test: 101\n",
            "0.75 0.8105263157894737 0.693069306930693 0.7586206896551724 0.5060008218899953 0.7517978113600834 0.5035956227201668 [0.01557469 0.01674294 0.02331495 0.01882792 0.01587272 0.02170634\n",
            " 0.01498127 0.01882124 0.0162878  0.01981807 0.01750851 0.0167644\n",
            " 0.01639199 0.01858544 0.01795292 0.01460981 0.01514196 0.01341248\n",
            " 0.01711822 0.01305199 0.01851058 0.02240491 0.01460004 0.0222919\n",
            " 0.02016377 0.01849365 0.01570773 0.02002048 0.01689768 0.01929545\n",
            " 0.01962662 0.01421142 0.01993322 0.01600981 0.03450012 0.01699352\n",
            " 0.01701641 0.0388155  0.01978374 0.01816535 0.01684833 0.01740432\n",
            " 0.01970053 0.02081656 0.01705503 0.01819348 0.01675034 0.01677012\n",
            " 0.01369238 0.01818728 0.01846671 0.01771951 0.01804495 0.01877618\n",
            " 0.0188446  0.01442313 0.0169549  0.016289   0.02130532 0.02151537\n",
            " 0.01473331 0.01485395 0.02001953 0.01791835 0.02000785 0.01870942\n",
            " 0.01847506 0.01938701 0.01411009 0.01556039 0.02076459 0.01714754\n",
            " 0.01801276 0.01732373 0.01692128 0.01405931 0.02075338 0.01260829\n",
            " 0.01719451 0.02735066 0.01851916 0.0233376  0.01494479 0.01934481\n",
            " 0.02091932 0.0195322  0.01691318 0.01971579 0.02023292 0.02172041\n",
            " 0.01842403 0.02108932 0.04355121 0.01966572 0.01916933 0.02162337\n",
            " 0.01791549 0.02350783 0.01782775 0.01826549 0.01776767 0.02024412\n",
            " 0.01725364 0.01860046 0.01691389 0.0209682  0.01814246 0.01895833\n",
            " 0.01768637 0.01960421 0.02119565 0.02179623 0.01741552 0.02036357\n",
            " 0.01944995 0.01684618 0.0187242  0.01846147 0.01946259 0.02033043\n",
            " 0.01440978 0.01720929 0.01374555 0.01805925 0.01152039 0.01190257\n",
            " 0.01338696 0.01525974 0.01443338 0.01836801 0.01671982 0.01750875\n",
            " 0.01611352 0.01525235 0.01886439 0.01855731 0.0177052  0.01805043\n",
            " 0.01818967 0.01919913 0.01605868 0.01791954 0.02044797 0.01297069\n",
            " 0.01260304 0.02109194 0.0207777  0.01274323 0.01376462 0.04184937\n",
            " 0.01238084 0.01575112 0.01638436 0.01479554 0.01521707 0.01557183\n",
            " 0.01629782 0.01969051 0.02024174 0.0164609  0.01597691 0.02141428\n",
            " 0.01482224 0.01540065 0.01776958 0.01944971 0.0169909  0.01801038\n",
            " 0.02206039 0.01917696 0.01697016 0.01617718 0.02004743 0.01943803\n",
            " 0.01693583 0.01955938 0.01617789 0.02302837 0.0241859  0.0173893\n",
            " 0.01875305 0.01959467 0.01973724 0.01807141 0.02015138 0.01937342\n",
            " 0.02088666 0.01834559 0.01714611 0.01659989 0.01577997 0.0152998\n",
            " 0.01838613 0.01864386 0.01696658 0.01415515]\n",
            "SAVING... ACP_KSRC_STATS_CKSAAP_GAP8 SOLVER_MP_PC30.mat\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAfVUlEQVR4nO3deXRV9bn/8ffTyBBlUCDSQEBiCF4CMiUFWU4UUakgqKCAlQJiqf5K1Xqdbx3bXnH41YvKz4JVcKgEcQpWhVUBKyiDiUaEOBBigISIYSigAZH4/f1xktxMJCfhnOycfT6vtVgre+9v9nm+OcnDc549mXMOERGJfD/xOgAREQkNJXQREZ9QQhcR8QkldBERn1BCFxHxieO8euFOnTq5Hj16ePXyIiIRKSsra5dzLq62bZ4l9B49epCZmenVy4uIRCQz23q0bWq5iIj4hBK6iIhPKKGLiPiEErqIiE8ooYuI+ES9Cd3MnjGzb8xs41G2m5k9Zma5ZrbBzAaFPkwREalPMBX6AmBkHdt/ASSX/ZsBPHnsYYmISEPVex66c+49M+tRx5CxwHMucB/etWZ2opnFO+eKQhSjiESZF9dtIyO7EICULu245+I+ANyY/jFF+w5VGTvolJO4beR/AHDt81nsLTlcZfuZPTtx/XnJAEx5Zj2Hfiitsv283icz45wkACbMXVMjltH94pk8tAcHD5cydf76GtvHpyZweVo39nx3mOteyKqx/aozTuHi/l3Y8e+D/H5RNgCLfjO0/h9CI4Sih94V2F5puaBsXQ1mNsPMMs0ss7i4OAQvLSJ+lJFdSE7Rfq/DiDgWzAMuyir0fzjn+tay7R/ALOfc6rLl5cBtzrk6LwNNS0tzulJUJDq8uG4b67/azf9MHAjAfW9sImdH1YR9atwJPHBZPwB63P4mQxI7hK2SjWRmluWcS6ttWygq9EKgW6XlhLJ1IiJAoOJ+PXtH0OMnDe7G2AG1ftCXOoTiXi5LgJlmlg4MAfapfy7SNCr3mit78qpUOpzQksWZ23k5q6DG9gXTBhPbMobn1+Tzjw01/1zLK+N5721h+WffVNnWukUMz149GIDHlm/m/dxdVbafdHxL/jo5FYAHl37OR1v3klO0nyGJHSrGlPfEj6a8UpeGqTehm9lCYBjQycwKgHuAFgDOub8CbwEXAblACTAtXMGKSFVtWx/HgUNHaNvas/vsBSUlvp0q7iYQVA89HNRDF6nbi+u2MeTUDiTFteGdnJ08tSqvxphHJwygy4mxHkQnXgl3D11EwiAju5An393idRgSQZr35zSRKLd9TwkAI1I6MyKls8fRSHOnhC5R4cV122gRYw2+AKSyX599KiNSOrOl+FvufPXTGtt/NzyZs5I7sWnHPu5/I6fG9ltHnkbqKR3I2rqHh5Z+UWP73Ren0KdLe1Zv3sXjKzaTU7SflPh2jZyxRCO1XCQqZGQX8uS/Iqt9oQOJ0lA6KCoRLdhLtcurXV2oIpFOB0Ul6qnalWigHrpEhOo3Vfpy5wGuG5ZUZ8Ud2zJGFblEFVXoEpF6dW5Lm1YtvA5DpFlRhS7NSvXbn24o2Md1w5IqLjUXkaNThS7NWr+E9nRq08rrMEQigip0aRYeXPo5QMVNnUSk4ZTQpVn4aOter0MQiXhquYiI+IQSuoiITyihi4j4hHro0izEt2/tdQgiEU8JXZrUHa9uIK/4uyrrUrq0q3h4sIg0nlouEnZ3vLqBO17d4HUYIr6nCl3CrnJFrof/ioSPKnQREZ9QQpewuu+NTeQU7fc6DJGooIQuYad7kYs0DfXQJSxuTP8YQGeviDQhJXQJi6J9h7wOQSTqqOUiIuITSugiIj6hhC4i4hPqoUtYDDrlJK9DEIk6SugSFreN/A+vQxCJOkrocsweW76Z93N3VVl30vEt9Tg5kSamHrqIiE8EVaGb2UhgNhAD/M05N6va9u7As8CJZWNud869FeJYJcyeX5PPPzYU1Vi/6DdDAZj33haWf/ZNlW2tW8Tw7NWDuf685KYIUUTqUG+FbmYxwBzgF0AKMMnMUqoN+wPwknNuIDAR+H+hDlTC5+DhUg4eLvU6DBE5RsFU6IOBXOdcHoCZpQNjgZxKYxzQruzr9sCOUAYp4TV1/nogUIlPHtrjqONmnJPEjHOSmigqEWmoYHroXYHtlZYLytZVdi9wlZkVAG8Bv6ttR2Y2w8wyzSyzuLi4EeGKiMjRhOqg6CRggXMuAbgIeN7MauzbOTfPOZfmnEuLi4sL0UuLiAgEl9ALgW6VlhPK1lU2HXgJwDm3BmgNdApFgCIiEpxgEvqHQLKZJZpZSwIHPZdUG7MNOA/AzHoTSOjqqYiINKF6D4o6546Y2UxgGYFTEp9xzm0ys/uBTOfcEuA/gafM7PcEDpBOdc65cAYuoTM+NcHrEEQkBMyrvJuWluYyMzM9eW0RkUhlZlnOubTatulKUWHPd4fZ891hr8MQkWOke7kI172QBfzvFaEiEplUoYuI+IQqdJ97cd02MrKrnmX66IQBdDkxljc+2cELa7eSU7SflPh2R9mDiEQKVeg+l5FdSE7R/jrHpMS3Y+yA6hf/ikik0VkuEaZyxX33xSn06dKe1Zt38fiKzTXG/vdlp/NV8XcAjEjp3KRxikh41HWWi1ouEaa84g62RaJELhI9lNCbkdr63QC3jjyN1FM6kLV1T0Uyr3xGylnJnTgrWXdaEIl26qE3I/27tSeubas6x6jfLSJHox66iEgE0ZWiEWL15l2s3ryr/oEiIrVQD70ZKT9TRf1wEWkMVegiIj6hhC4i4hNK6CIiPqGELiLiEzoo6oHaLiD69dmn8t+Xne5RRCLiB6rQPXC0G2YlxbUhKa6NBxGJiB+oQm8ClSvyq844hUcnDACgy4mxXoYlIj6jCr0JVK/Iu5wYq2QuIiGnCr2JVL+hlohIqKlCFxHxCVXoYVLeNx+fmsCTV6V6HY6IRAEl9DCp3DfvcEJLj6MRkWiglksYpcS34/K0bl6HISJRQgldRMQnlNBFRHxCPfQwWTBtsNchiEiUUUIPk9iWMV6HICJRRi2XMHl+TT7Pr8n3OAoRiSZBVehmNhKYDcQAf3POzaplzBXAvYADPnHOXRnCOJuVyvdmOa/3ycw4JwmACXPXVIzJKdpPSnw7Jg/t4UWIIhKF6k3oZhYDzAHOBwqAD81siXMup9KYZOAO4Ezn3F4zOzlcATcH5eeYp8S3O+qYlPh2jB3QtQmjEpFoF0yFPhjIdc7lAZhZOjAWyKk05tfAHOfcXgDn3DehDrQpXft8FntLDldZd2bPTlx/XjIA677aw5DEDjXuzaJ7tYiIl4LpoXcFtldaLihbV1kvoJeZvW9ma8taNDWY2QwzyzSzzOLi4sZF3Ayc2ytO1beINDuhOsvlOCAZGAYkAO+Z2enOuX9XHuScmwfMA0hLS3Mheu2Q++vkuu+98uzVOiVRRJqfYCr0QqDy9esJZesqKwCWOOd+cM59BXxJIMFHnAeXfs6DSz/3OgwRkQYLJqF/CCSbWaKZtQQmAkuqjXmdQHWOmXUi0ILJC2GcTeajrXv5aOter8MQEWmwehO6c+4IMBNYBnwGvOSc22Rm95vZmLJhy4DdZpYDrARucc7tDlfQIiJSU1A9dOfcW8Bb1dbdXelrB9xU9k9ERDygK0VFRHxC93KpJr59a69DEBFpFCX0av5n4kCvQxARaRS1XEREfEIJvZr73tjEfW9s8joMEZEGU8ulmpwd+70OQUSkUVShi4j4hBK6iIhPKKGLiPiEeujVnBp3gtchiIg0ihJ6NQ9c1s/rEEREGkUtFxERn1BCr+aOVzdwx6sbvA5DRKTB1HKpJq/4O69DEBFplKit0F9ct40b0z+uWL7vjU1MmLuGnCJdWCQikSlqE3pGdiGvZ++osT4lvp0eAC0iESmqWy5DEjtUfH3PxX08jERE5NhFbYUuIuI3SugiIj4RtS2XQaec5HUIIiIhFVUJ/cV128jILuSk41vy18mpXocjIhJSUdVyycgu1GmJIuJbUZXQIXBaoqpzEfGjqEvoIiJ+FVU99DN7dvI6BBGRsImqhH79eclehyAiEjZquYiI+ERUJfQpz6xnyjPrvQ5DRCQsoqrlcuiHUq9DEBEJm6iq0EVE/EwJXUTEJ4JK6GY20sy+MLNcM7u9jnHjzMyZWVroQhQRkWDU20M3sxhgDnA+UAB8aGZLnHM51ca1BW4A1oUj0FA4r/fJXocgIhI2wRwUHQzkOufyAMwsHRgL5FQb90fgQeCWkEYYQjPOSfI6BBGRsAmm5dIV2F5puaBsXQUzGwR0c869WdeOzGyGmWWaWWZxcXGDgxURkaM75oOiZvYT4C/Af9Y31jk3zzmX5pxLi4uLO9aXbrAJc9cwYe6aJn9dEZGmEExCLwS6VVpOKFtXri3QF3jXzPKBM4AlOjAqItK0gknoHwLJZpZoZi2BicCS8o3OuX3OuU7OuR7OuR7AWmCMcy4zLBGLiEit6k3ozrkjwExgGfAZ8JJzbpOZ3W9mY8IdoIiIBCeoS/+dc28Bb1Vbd/dRxg479rBERKShoupeLqP7xXsdgohI2ERVQp88tIfXIYiIhE1U3cvl4OFSDh7WHRdFxJ+iKqFPnb+eqfN1P3QR8aeoSugiIn6mhC4i4hNK6CIiPqGELiLiE1F12uL41ASvQxARCZuoSuiXp3Wrf5CISISKqpbLnu8Os+e7w16HISISFlFVoV/3QhYAi34z1ONIRERCL6oqdBERP1NCFxHxCSV0ERGfUEIXEfGJqDooetUZp3gdgohI2ERVQr+4fxevQxARCZuoarns+PdBdvz7oNdhiIiERVRV6L9flA3oPHQR8aeoqtBFRPxMCV1ExCeU0EVEfEIJXUTEJ6LqoOivzz7V6xBERMImqhL6iJTOXocgIhI2UdVy2VL8LVuKv/U6DBGRsIiqCv3OVz8FdB66iPhTVFXoIiJ+poQuIuITQSV0MxtpZl+YWa6Z3V7L9pvMLMfMNpjZcjPTbQ1FRJpYvQndzGKAOcAvgBRgkpmlVBv2MZDmnOsHvAw8FOpARUSkbsEcFB0M5Drn8gDMLB0YC+SUD3DOraw0fi1wVSiDDJXfDU/2OgQRkbAJJqF3BbZXWi4AhtQxfjrwdm0bzGwGMAOge/fuQYYYOmcld2ry1xQRaSohPShqZlcBacDDtW13zs1zzqU559Li4uJC+dJB2bRjH5t27Gvy1xURaQrBVOiFQLdKywll66owsxHAfwHnOue+D014oXX/G4Eukc5DFxE/CqZC/xBINrNEM2sJTASWVB5gZgOBucAY59w3oQ9TRETqU29Cd84dAWYCy4DPgJecc5vM7H4zG1M27GGgDbDYzLLNbMlRdiciImES1KX/zrm3gLeqrbu70tcjQhyXiIg0kK4UFRHxiai6OdetI0/zOgQRkbCJqoSeekoHr0MQEQmbqGq5ZG3dQ9bWPV6HISISFlGV0B9a+gUPLf3C6zBERMIiqhK6iIifRUVC37RjHxPmriGnaL/XoYiIhE1UJPRyKfHtGDugq9dhiIiEhe/Pclm9eReg+7eIiP/5PqE/vmIzoFvnioj/RVXLRUTEz5TQRUR8wtcJfUvxtzqzRUSihi976O/k7AQgMe4EndkiIlHDlwn9qVV5QODMFp3dIiLRwtctFxGRaKKELiLiE0roIiI+oYQuIuITvjwo+uiEAV6HICLS5HyZ0LucGOt1CNLM/fDDDxQUFHDo0CGvQxGpVevWrUlISKBFixZBf48vE/obn+wA4OL+XTyORJqrgoIC2rZtS48ePTAzr8MRqcI5x+7duykoKCAxMTHo7/NlD/2FtVt5Ye1Wr8OQZuzQoUN07NhRyVyaJTOjY8eODf4EGdEV+ovrttEixrg8rRt7vjvMdS9kAZBTtJ+U+HYeRyfNnZK5NGeN+f2M6Ao9I7uQJ/+1pcZ6Xe4vItEo4ir0F9dtIyO7EKhaiXc4oaUu8xeRqBZxFfqlA7syJLEDoEpcIt/rr7+OmfH5559XWb9+/XrOOeccTjvtNAYOHMg111xDSUkJCxYsIC4ujgEDBpCSksJTTz111H3v3LmT0aNH079/f1JSUrjooosAyM/PJzY2tmIfv/rVr/jhhx+AwNk/t99+O8nJyQwaNIihQ4fy9ttv17r/8ePHk5eXV7GcnZ2NmbF06dKKdfn5+fTt27fK991777088sgjAEydOpXExEQGDBhA//79Wb58ecW4w4cPc+ONN9KzZ0+Sk5MZO3YsBQUFFdu//vprJk6cSFJSEqmpqVx00UV8+eWXdf686/P9998zYcIEevbsyZAhQ8jPz6913KOPPkqfPn3o27cvkyZNqtHrvv7662nTpk2N73vllVcwMzIzMwH49NNPmTp16jHFXFnEVeixLWO46YLTvA5DfGbC3DU11o3uF8/koT04eLiUqfPX19g+PjWhxvGbcsF+Wly4cCFnnXUWCxcu5L777gMCifjyyy8nPT2doUMD+3n55Zc5cOBAINYJE3jiiSf45ptv6NOnD2PGjKFz58419n333Xdz/vnnc8MNNwCwYcOGim1JSUlkZ2dTWlrK+eefz0svvcQvf/lL7rrrLoqKiti4cSOtWrVi586d/Otf/6qx702bNlFaWsqpp55a61xGjhwZ1PwBHn74YcaPH8/KlSuZMWMGmzcHnjJ25513cuDAAb744gtiYmKYP38+l112GevWrQPg0ksvZcqUKaSnpwPwySefsHPnTnr16hX0a1f39NNPc9JJJ5Gbm0t6ejq33XYbixYtqjKmsLCQxx57jJycHGJjY7niiitIT0+vSMyZmZns3bu3xr4PHDjA7NmzGTJkSMW6008/nYKCArZt20b37t0bHXe5iKvQn1+Tz/Nr8j2OQuTYffvtt6xevZqnn366IikBzJkzhylTplQkcwhUw9WT9sknn0xSUhJbt9Z+RldRUREJCQkVy/369asxJiYmhsGDB1NYWEhJSQlPPfUUjz/+OK1atQKgc+fOXHHFFTW+7+9//ztjx46tWHbOsXjxYhYsWMA///nPRp3fP3ToUAoLA+3UkpIS5s+fz6OPPkpMTAwA06ZNo1WrVqxYsYKVK1fSokULrr322orv79+/P2effXaDX7eyjIwMpkyZAgR+5suXL8c5V2PckSNHOHjwIEeOHKGkpIQuXQKnSJeWlnLLLbfw0EMP1fieu+66i9tuu43WrVtXWX/xxRdXef+PRcRV6P/YUATA5KE9vA1EfKWuijq2ZUyd2xt7/CYjI4ORI0fSq1cvOnbsSFZWFqmpqWzcuLEiqdQlLy+PvLw8evbsWev23/72txXV/IgRI5g2bVpF4il36NAh1q1bx+zZs8nNzaV79+60a1f/GWLvv/8+kyZNqlj+4IMPSExMJCkpiWHDhvHmm28ybty4evdT2dKlS7nkkksAjhpLWloamzZtAiA1NTWo/Z599tkVn24qe+SRRxgxYkSVdYWFhXTr1g2A4447jvbt27N79246dfrfZxJ37dqVm2++me7duxMbG8sFF1zABRdcAMATTzzBmDFjiI+Pr7Lfjz76iO3btzNq1CgefvjhGnOaNWsWt956a1DzqUvEJXQRv1i4cGFFO2TixIksXLgwqCS1aNEiVq9eTatWrZg7dy4dOnSoddyFF15IXl4eS5cu5e2332bgwIFs3LgRgC1btjBgwAC++uorRo0aRb9+/aq0ZOpTVFREXFxclblMnDixYi7PPfcc48aNO+qpd5XX33LLLdx5550UFBSwZk3N1texWrVqVUj3t3fvXjIyMvjqq6848cQTufzyy3nhhRcYPnw4ixcv5t13360y/scff+Smm25iwYIFte7v5JNPZseOHSGJLaiEbmYjgdlADPA359ysattbAc8BqcBuYIJzLj8kEYr40J49e1ixYgWffvopZkZpaSlmxsMPP0yfPn3Iysqq0tKorLzqDkaHDh248sorufLKKxk9ejTvvfceqampFT30Xbt2ceaZZ7JkyRJGjBjBtm3b2L9/f71VemxsbEVbpbS0lFdeeYWMjAz+/Oc/V1zleODAATp27Fijn7xnz54qVz+W99Aff/xxrr76arKyskhKSmLbtm0cOHCAtm3bVozNyspi9OjRQOC4QjAaUqF37dqV7du3k5CQwJEjR9i3bx8dO3asMuadd94hMTGx4j+0yy67jA8++KCi917+iamkpISePXuSlZXFxo0bGTZsGBA4mDtmzBiWLFlCWloahw4dIjY2NLcrqbeHbmYxwBzgF0AKMMnMUqoNmw7sdc71BB4FHgxJdCI+9fLLLzN58mS2bt1Kfn4+27dvJzExkVWrVjFz5kyeffbZioN/AK+++io7d+5s0GusWLGCkpISIHBAbsuWLTUOvHXq1IlZs2bxwAMPcPzxxzN9+nRuuOEGDh8+DEBxcTGLFy+use/evXuTm5sLwPLly+nXrx/bt28nPz+frVu3Mm7cOF577TXatGlDfHw8K1asAALJfOnSpZx11lk19jlz5kx+/PFHli1bxgknnMCUKVO46aabKC0tBeC5556jpKSE4cOHM3z4cL7//nvmzZtX8f0bNmyotRpftWoV2dnZNf5VT+YAY8aM4dlnnwUC79Hw4cNrfMro3r07a9eupaSkBOccy5cvp3fv3owaNYqvv/6a/Px88vPzOf7448nNzaV9+/bs2rWrYv0ZZ5xRkcwBvvzyyxpnAjVWMAdFBwO5zrk859xhIB2oXjqMBZ4t+/pl4DzTZXgiR7Vw4UIuvfTSKuvGjRvHwoUL6dy5M+np6dx8882cdtpp9O7dm2XLllWpVIORlZVFWloa/fr1Y+jQoVxzzTX87Gc/qzHukksuoaSkhFWrVvGnP/2JuLg4UlJS6Nu3L6NHj661Wh81alRFa6GuuUAgEf/xj39kwIABDB8+nHvuuYekpKQa+zQz/vCHP1QcUHzggQdo3bo1vXr1Ijk5mcWLF/Paa69hZpgZr732Gu+88w5JSUn06dOHO+64g5/+9KcN+hlVN336dHbv3k3Pnj35y1/+wqxZgWbEjh07Kk77HDJkCOPHj2fQoEGcfvrp/Pjjj8yYMaPRr7ly5UpGjRp1THGXs9qO4FYZYDYeGOmcu6ZseTIwxDk3s9KYjWVjCsqWt5SN2VVtXzOAGQDdu3dPPdrReZFw++yzz+jdu7fXYUSsgwcP8vOf/5z333+/4iwUabjvv/+ec889l9WrV3PccTU74LX9nppZlnMurbb9Nelpi865ec65NOdcWuUDKiISWWJjY7nvvvsqTjOUxtm2bRuzZs2qNZk3RjB7KQS6VVpOKFtX25gCMzsOaE/g4KiIhNn8+fOZPXt2lXVnnnkmc+bMCevrXnjhhWHdfzRITk4mOTk5ZPsLJqF/CCSbWSKBxD0RuLLamCXAFGANMB5Y4err5Yh4zDnnizsuTps2jWnTpnkdhoRYY1JovS0X59wRYCawDPgMeMk5t8nM7jezMWXDngY6mlkucBNwe4MjEWlCrVu3Zvfu3Y36oxEJt/JTP6tfVVqfeg+KhktaWporv0GNSFPTI+ikuTvaI+jqOiiqK0UlKrVo0aJBj/YSiQQRd3MuERGpnRK6iIhPKKGLiPiEZwdFzawYaOylop2AXfWO8hfNOTpoztHhWOZ8inOu1iszPUvox8LMMo92lNevNOfooDlHh3DNWS0XERGfUEIXEfGJSE3o8+of4juac3TQnKNDWOYckT10ERGpKVIrdBERqUYJXUTEJ5p1QjezkWb2hZnlmlmNOziaWSszW1S2fZ2Z9Wj6KEMriDnfZGY5ZrbBzJab2SlexBlK9c250rhxZubMLOJPcQtmzmZ2Rdl7vcnMXmzqGEMtiN/t7ma20sw+Lvv9vsiLOEPFzJ4xs2/KnuhW23Yzs8fKfh4bzGzQMb+oc65Z/gNigC3AqUBL4BMgpdqY/wP8tezricAir+Nugjn/HDi+7OvromHOZePaAu8Ba4E0r+Nugvc5GfgYOKls+WSv426COc8Driv7OgXI9zruY5zzOcAgYONRtl8EvA0YcAaw7lhfszlX6NH4cOp65+ycW+mcKylbXEvgCVKRLJj3GeCPwIOAH+53G8ycfw3Mcc7tBXDOfdPEMYZaMHN2QPkTqdsDO5owvpBzzr0H7KljyFjgORewFjjRzOKP5TWbc0LvCmyvtFxQtq7WMS7wII59QMcmiS48gplzZdMJ/A8fyeqdc9lH0W7OuTebMrAwCuZ97gX0MrP3zWytmY1ssujCI5g53wtcZWYFwFvA75omNM809O+9XrofeoQys6uANOBcr2MJJzP7CfAXYKrHoTS14wi0XYYR+BT2npmd7pz7t6dRhdckYIFz7v+a2VDgeTPr65z70evAIkVzrtAb8nBqfPJw6mDmjJmNAP4LGOOc+76JYguX+ubcFugLvGtm+QR6jUsi/MBoMO9zAbDEOfeDc+4r4EsCCT5SBTPn6cBLAM65NUBrAjex8qug/t4bojkn9IqHU5tZSwIHPZdUG1P+cGrwx8Op652zmQ0E5hJI5pHeV4V65uyc2+ec6+Sc6+Gc60HguMEY51wkP78wmN/t1wlU55hZJwItmLymDDLEgpnzNuA8ADPrTSChFzdplE1rCfCrsrNdzgD2OeeKjmmPXh8Jruco8UUEKpMtwH+VrbufwB80BN7wxUAusB441euYm2DO7wA7geyyf0u8jjncc6429l0i/CyXIN9nI9BqygE+BSZ6HXMTzDkFeJ/AGTDZwAVex3yM810IFAE/EPjENR24Fri20ns8p+zn8Wkofq916b+IiE8055aLiIg0gBK6iIhPKKGLiPiEErqIiE8ooYuI+IQSuoiITyihi4j4xP8Hm8pKWqoCNzwAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fn2GeFF5aARl"
      },
      "id": "fn2GeFF5aARl",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}